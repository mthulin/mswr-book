# Solutions to exercises {#solutions}

## Chapter 2{-#solutionsch2}

#### Exercise \@ref(exr:ch2bexc1) {-#ch2bsolutions1}
Type the following code into the Console window:

```{r eval=FALSE}
1 * 2 * 3 * 4 * 5 * 6 * 7 * 8 * 9 * 10
```

The answer is $3,628,800$.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc1)


#### Exercise \@ref(exr:ch2bexc2) {-#ch2bsolutions2}
1. To compute the sum and assign it to `a`, we use:

```{r eval=FALSE}
a <- 924 + 124
``` 

2. To compute the square of `a` we can use:
```{r eval=FALSE}
a*a
```
The answer is $1,098,304$.

As you'll soon see in other examples, the square can also be computed using:
```{r eval=FALSE}
a^2
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc2)

#### Exercise \@ref(exr:ch2bexc3) {-#ch2bsolutions3}
1. When an invalid character is used in a variable name, an error message is displayed in the Console window. Different characters will render different error messages. For instance, `net-income <- income - taxes` yields the error message `Error in net - income <- income - taxes : object 'net' not found`. This may seem a little cryptic (and it is!), but what it means is that R is trying to compute the difference between the variables `net` and `income`, because that is how R interprets `net-income`, and fails because the variable `net` does not exist. As you become more experienced with R, the error messages will start making more and more sense (at least in most cases).

2. If you put R code as a comment, it will be treated as a comment, meaning that it won't run. This is actually hugely useful, for instance when you're looking for errors in your code - you can comment away lines of code and see if the rest of the code runs without them.

3. Semicolons can be used to write multiple commands on a single line - both will run as if they were on separate lines. If you like, you can add more semicolons to run even more commands.

4. The value to the right is assigned to both variables. Note, however, that any operations you perform on one variable won't affect the other. For instance, if you change the value of one of them, the other will remain unchanged:

```{r eval=FALSE}
income2 <- taxes2 <- 100
income2; taxes2 # Check that both are 100
taxes2 <- 30 # income2 doesn't change
income2; taxes2 # Check values
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc3)

#### Exercise \@ref(exr:ch2bexc4) {-#ch2bsolutions4}
1. To create the vectors, use `c`:
```{r eval=FALSE}
height <- c(158, 170, 172, 181, 196)
weight <- c(45, 80, 62, 75, 115)
```

2. To combine the two vectors into a data frame, use `data.frame`
```{r eval=FALSE}
hw_data <- data.frame(height, weight)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc4)

#### Exercise \@ref(exr:ch2bexc4b) {-#ch2bsolutions4b}
The vector created using:

```{r eval=FALSE}
x <- 1:5
```

is $(1,2,3,4,5)$. Similarly,

```{r eval=FALSE}
x <- 5:1
```

gives us the same vector in reverse order: $(5,4,3,2,1)$. To create the vector $(1,2,3,4,5,4,3,2,1)$ we can therefore use:

```{r eval=FALSE}
x <- c(1:5, 4:1)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc4b)

#### Exercise \@ref(exr:ch2bexc5) {-#ch2bsolutions5}
1. To compute the mean height, use the `mean` function:
```{r eval=FALSE}
mean(height)
```

2. To compute the correlation between the two variables, use `cor`:
```{r eval=FALSE}
cor(height, weight)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc5)

#### Exercise \@ref(exr:ch2bexc6) {-#ch2bsolutions6}
1. `length` computes the length (i.e. the number of elements) of a vector. `length(height)` returns the value `5`, because the vector is 5 elements long.

2. `sort` sorts a vector. The parameter `decreasing` can be used to decide whether the elements should be sorted in ascending (`sort(weights, decreasing = FALSE)`) or descending (`sort(weights, decreasing = TRUE)`) order. To sort the weights in ascending order, we can use `sort(weight)`. Note, however, that the resulting sorted vector won't be stored in the variable `weight` unless we write `weight <- sort(weight)`!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc6)


#### Exercise \@ref(exr:ch2bexc7) {-#ch2bsolutions7}
1. $\sqrt{\pi}=1.772454\ldots$:
```{r eval=FALSE}
sqrt(pi)
```

2. $e^2\cdot log(4)=10.24341\ldots$:
```{r eval=FALSE}
exp(2)*log(4)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc7)


#### Exercise \@ref(exr:ch2bexc8) {-#ch2bsolutions8}
1. The expression $1/x$ tends to infinity as $x\rightarrow 0$, and so R returns $\infty$ as the answer in this case:
```{r eval=FALSE}
1/0
```

2. The division $0/0$ is undefined, and R returns `NaN`, which stands for Not a Number:
```{r eval=FALSE}
0/0
```

3. $\sqrt{-1}$ is undefined (as long as we stick to real numbers), and so R returns `NaN`. The `sqrt` function also provides an error message saying that `NaN` values were produced.
```{r eval=FALSE}
sqrt(-1)
```

If you want to use complex numbers for some reason, you can write the complex number $a+bi$ as `complex(1, a, b)`\index{\texttt{complex}}. Using complex numbers, the square root of $-1$ is $i$:

```{r eval=FALSE}
sqrt(complex(1, -1, 0))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2bexc8)

#### Exercise \@ref(exr:ch2exc1) {-#solutions1}
1. View the documentation, where the data is described:

```{r eval=FALSE}
?diamonds 
```

2. Have a look at the structure of the data:

```{r eval=FALSE}
str(diamonds)
```

This shows you the number of observations (53,940) and variables (10), and the variable types. There are three different data types here: `num` (numerical), `Ord.factor` (ordered factor, i.e. an ordered categorical variable) and `int` (integer, a numerical variable that only takes integer values).

3. To compute the descriptive statistics, we can use:

```{r eval=FALSE}
summary(diamonds)
```

In the summary, missing values show up as NA's. There are no NA's here, and hence no missing values.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc1)

#### Exercise \@ref(exr:ch2exc2) {-#solutions2}
```{r eval=FALSE}
ggplot(msleep, aes(sleep_total, awake)) +
      geom_point()
```

The points follow a declining line. The reason for this is that at any given time, an animal is either awake or asleep, so the total sleep time plus the awake time is always 24 hours for all animals. Consequently, the points lie on the line given by `awake=24-sleep_total`.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc2)

#### Exercise \@ref(exr:ch2exc3) {-#solutions3}
1.
```{r eval=FALSE}
ggplot(diamonds, aes(carat, price, colour = cut)) +
      geom_point() +
      xlab("Weight of diamond (carat)") +
      ylab("Price (USD)")
```

2. We can change the opacity of the points by adding an `alpha` argument to `geom_point`. This is useful when the plot contains overlapping points:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price, colour = cut)) +
      geom_point(alpha = 0.25) +
      xlab("Weight of diamond (carat)") +
      ylab("Price (USD)")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc3)

#### Exercise \@ref(exr:ch2exc4) {-#solutions4}
1. To set different shapes for different values of `cut` we use:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price, colour = cut, shape = cut)) +
      geom_point(alpha = 0.25) +
      xlab("Weight of diamond (carat)") +
      ylab("Price (USD)")
```

2. We can then change the size of the points as follows. The resulting figure is unfortunately not that informative in this case.

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price, colour = cut,
                     shape = cut, size = x)) +
      geom_point(alpha = 0.25) +
      xlab("Weight of diamond (carat)") +
      ylab("Price (USD)")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc4)

#### Exercise \@ref(exr:ch2exc5) {-#solutions5}
Using the `scale_axis_log10` options:

```{r eval=FALSE}
ggplot(msleep, aes(bodywt, brainwt, colour = sleep_total)) + 
      geom_point() +
      xlab("Body weight (logarithmic scale)") +
      ylab("Brain weight (logarithmic scale)") +
      scale_x_log10() +
      scale_y_log10()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc5)


#### Exercise \@ref(exr:ch2exc6)  {-#solutions6}
1. We use `facet_wrap(~ cut)` to create the facetting:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price)) + 
      geom_point() +
      facet_wrap(~ cut)
```

2. To set the number of rows, we add an `nrow` argument to `facet_wrap`:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price)) + 
      geom_point() +
      facet_wrap(~ cut, nrow = 5)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc6)


#### Exercise \@ref(exr:ch2exc7) {-#solutions7}
1.
```{r eval=FALSE}
ggplot(diamonds, aes(cut, price)) +
      geom_boxplot()
```

2. To change the colours of the boxes, we add `colour` (outline colour) and `fill` (box colour) arguments to `geom_boxplot`:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, price)) +
      geom_boxplot(colour = "magenta", fill = "turquoise")
```

(No, I don't really recommend using this particular combination of colours.)

3. `reorder(cut, price, median)` changes the order of the `cut` categories based on their median `price` values.

```{r eval=FALSE}
ggplot(diamonds, aes(reorder(cut, price, median), price)) +
      geom_boxplot(colour = "magenta", fill = "turquoise")
```

4. `geom_jitter` can be used to plot the individual observations on top of the histogram. Because there are so many observations in this dataset, we must set a small size and a low alpha in order not to cover the boxes completely.

```{r eval=FALSE}
ggplot(diamonds, aes(reorder(cut, price), price)) +
      geom_boxplot(colour = "magenta", fill = "turquoise") +
      geom_jitter(size = 0.1, alpha = 0.2)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc7)


#### Exercise \@ref(exr:ch2exc8) {-#solutions8}
1. 
```{r eval=FALSE}
ggplot(diamonds, aes(price)) +
      geom_histogram()
```

2. Next, we facet the histograms using `cut`:

```{r eval=FALSE}
ggplot(diamonds, aes(price)) +
      geom_histogram() +
      facet_wrap(~ cut)
```

3. Finally, by reading the documentation `?geom_histogram` we find that we can add outlines using the `colour` argument:

```{r eval=FALSE}
ggplot(diamonds, aes(price)) +
      geom_histogram(colour = "black") +
      facet_wrap(~ cut)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc8)

#### Exercise \@ref(exr:ch2exc9) {-#solutions9}
1.
```{r eval=FALSE}
ggplot(diamonds, aes(cut)) +
      geom_bar()
```

2. To set different colours for the bars, we can use `fill`, either to set the colours manually or using default colours (by adding a colour aesthetic):

```{r eval=FALSE}
# Set colours manually:
ggplot(diamonds, aes(cut)) +
      geom_bar(fill = c("red", "yellow", "blue", "green", "purple"))

# Use defaults:
ggplot(diamonds, aes(cut, fill = cut)) +
      geom_bar()
```

3. `width` lets us control the bar width:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, fill = cut)) +
      geom_bar(width = 0.5)
```

4. By adding `fill = clarity` to `aes` we create stacked bar charts:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, fill = clarity)) +
      geom_bar()
```

5. By adding `position = "dodge"` to `geom_bar` we obtain grouped bar charts:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, fill = clarity)) +
      geom_bar(position = "dodge")
```

6. `coord_flip` flips the coordinate system, yielding a horizontal bar plot:

```{r eval=FALSE}
ggplot(diamonds, aes(cut)) +
      geom_bar() +
      coord_flip()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc9)

#### Exercise \@ref(exr:ch2exc10) {-#solutions10}
To save the png file, use

```{r eval=FALSE}
myPlot <- ggplot(msleep, aes(sleep_total, sleep_rem)) +
      geom_point()

ggsave("filename.png", myPlot, width = 4, height = 4)
```

To change the resolution, we use the `dpi` argument:

```{r eval=FALSE}
ggsave("filename.png", myPlot, width = 4, height = 4, dpi=600)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch2exc10)



## Chapter 3 {-#solutionsch3}

#### Exercise \@ref(exr:ch3exc1) {-#ch3solutions1}
1. Both approaches render a `character` object with the text `A rainy day in Edinburgh`:

```{r eval=FALSE}
a <- "A rainy day in Edinburgh"
a
class(a)

a <- 'A rainy day in Edinburgh'
a
class(a)
```

That is, you are free to choose whether to use single or double quotation marks. I tend to use double quotation marks, because I was raised to believe that double quotation marks are superior in every way (well, that, and the fact that I think that they make code easier to read simply because they are easier to notice).

2. The first two sums are `numeric` whereas the third is `integer`
```{r eval=FALSE}
class(1 + 2)    # numeric
class(1L + 2)   # numeric
class (1L + 2L) # integer
```

If we mix `numeric` and `integer` variables, the result is a `numeric`. But as long as we stick to just `integer` variables, the result is usually an `integer`. There are exceptions though - computing `2L/3L` won't result in an `integer` because... well, because it's not an integer.
  
3. When we run `"Hello" + 1` we receive an error message:

```{r eval=FALSE}
> "Hello" + 1
Error in "Hello" + 1 : non-numeric argument to binary operator
```

In R, binary operators are mathematical operators like `+`, `-`, `*` and `/` that takes two numbers and returns a number. Because `"Hello"` is a `character` and not a `numeric`, it fails in this case. So, in English the error message reads `Error in "Hello" + 1 : trying to perform addition with something that is not a number`. Maybe you know a bit of algebra and want to say _hey, we_ can _add characters together, like in $a^2+b^2=c^2$!_. Which I guess is correct. But R doesn't do algebraic calculations, but numerical ones - that is, all letters involved in the computations must represent actual numbers. `a^2+b^2=c^2` will work only if `a`, `b` and `c` all have numbers assigned to them.
  
4. Combining `numeric` and a `logical` variables turns out to be very useful in some problems. The result is always numeric, with `FALSE` being treated as the number `0` and `TRUE` being treated as the number `1` in the computations:

```{r eval=FALSE}
class(FALSE * 2)
class(TRUE + 1)
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc1)

#### Exercise \@ref(exr:ch3exc1c) {-#ch3solutions1c}
The functions return information about the data frame:

```{r eval=FALSE}
ncol(airquality) # Number of columns of the data frame
nrow(airquality) # Number of rows of the data frame
dim(airquality) # Number of rows, followed by number of columns
names(airquality) # The name of the variables in the data frame
row.names(airquality) # The name of the rows in the data frame
                      # (indices unless the rows have been named)
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc1c)



#### Exercise \@ref(exr:ch3exc1b) {-#ch3solutions1b}
To create the matrices, we need to set the number of rows `nrow`, the number of columns `ncol` and whether to use the elements of the vector `x` to fill the matrix by rows or by columns (`byrow`). To create

$$\begin{pmatrix}
  1 & 2 & 3\\ 
  4 & 5 & 6
\end{pmatrix}$$

we use:

```{r eval=FALSE}
x <- 1:6

matrix(x, nrow = 2, ncol = 3, byrow = TRUE)
```

And to create

$$\begin{pmatrix}
  1 & 4\\ 
  2 & 5\\
  3 & 6
\end{pmatrix}$$

we use:

```{r eval=FALSE}
x <- 1:6

matrix(x, nrow = 3, ncol = 2, byrow = FALSE)
```

We'll do a deep-dive on `matrix` objects in Section \@ref(linearalgebra).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc1b)

#### Exercise \@ref(exr:ch3exc2) {-#ch3solutions2}
1. In the `[i, j]` notation, `i` is the row number and `j` is the column number. In this case, `airquality[, 3]`, we have j=3 and therefore asks for the 3rd _column_, not the 3rd row. To get the third row, we'd use `airquality[3,]` instead.
  
2. To extract the first five rows, we can use:

```{r eval=FALSE}
airquality[1:5,]
# or
airquality[c(1, 2, 3, 4, 5),]
```

3. First, we use `names(airquality)` to check the column numbers of the two variables. `Wind` is column 3 and `Temp` is column 4, so we can access them using `airquality[,3]` and `airquality[,4]` respectively. Thus, we can compute the correlation using:

```{r eval=FALSE}
cor(airquality[,3], airquality[,4])
```

Alternatively, we could refer to the variables using the column names:

```{r eval=FALSE}
cor(airquality[,"Wind"], airquality[,"Temp"])
```

4. To extract all columns except `Temp` and `Wind`, we use a minus sign `-` and a vector containing their indices:

```{r eval=FALSE}
airquality[, -c(3, 4)]
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc2)


#### Exercise \@ref(exr:ch3exc2p5) {-#ch3solutions2p5}
1. To add the new variable, we can use:

```{r eval=FALSE}
bookstore$rev_per_minute <- bookstore$purchase / bookstore$visit_length
```

2. By using `View(bookstore)` or looking at the data in the Console window using `bookstore`, we see that the customer in question is on row 6 of the data. To replace the value, we can use:

```{r eval=FALSE}
bookstore$purchase[6] <- 16
```

Note that the value of `rev_per_minute` hasn't been changed by this operation. We will therefore need to compute it again, to update its value:

```{r eval=FALSE}
# We can either compute it again for all customers:
bookstore$rev_per_minute <- bookstore$purchase / bookstore$visit_length
# ...or just for customer number 6:
bookstore$rev_per_minute[6] <- bookstore$purchase[6] / bookstore$visit_length[6]
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc2p5)




#### Exercise \@ref(exr:ch3exc3) {-#ch3solutions3}
1. The coldest day was the day with the lowest temperature:
```{r eval=FALSE}
airquality[which.min(airquality$Temp),]
```
  
We see that the 5th day in the period, May 5, was the coldest, with a temperature of 56 degrees Fahrenheit.
  
2. To find out how many days the wind speed was greater than 17 mph, we use `sum`:
```{r eval=FALSE}
sum(airquality$Wind > 17)
```
  
Because there are so few days fulfilling this condition, we could also easily have solved this by just looking at the rows for those days and counting them:
  
```{r eval=FALSE}
airquality[airquality$Wind > 17,]
```
  
3. Missing data are represented by `NA` values in R, and so we wish to check how many `NA` elements there are in the `Ozone` vector. We do this by combining `is.na` and `sum` and find that there are 37 missing values:

```{r eval=FALSE}
sum(is.na(airquality$Ozone))
```
  
4. In this case, we need to use an ampersand `&` sign to combine the two conditions:

```{r eval=FALSE}
sum(airquality$Temp < 70 & airquality$Wind > 10)
```

We find that there are 22 such days in the data.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc3)

#### Exercise \@ref(exr:ch3exc3b) {-#ch3solutions3b}
We should use the `breaks` argument to set the interval bounds in `cut`:

```{r eval=FALSE}
airquality$TempCat <- cut(airquality$Temp,
                          breaks = c(50, 70, 90, 110))
```

To see the number of days in each category, we can use `summary`:

```{r eval=FALSE}
summary(airquality$TempCat)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc3b)




#### Exercise \@ref(exr:ch3exc4) {-#ch3solutions4}
1. The variable `X` represents the empty column between `Visit` and `VAS`. In the `X.1` column the researchers have made comments on two rows (rows 692 and 1153), causing R to read this otherwise empty column. If we wish, we can remove these columns from the data using the syntax from Section \@ref(accessingelements):

```{r eval=FALSE}
vas <- vas[, -c(4, 6)]
```

2. We remove the `sep = ";"` argument:

```{r eval=FALSE}
vas <- read.csv(file_path, dec = ",", skip = 4)
```

...and receive the following error message:

```{r eval=FALSE}
Error in read.table(file = file, header = header, sep = sep,
                    quote = quote,  : 
  duplicate 'row.names' are not allowed
```

By default, `read.csv` uses commas, `,`, as column delimiters. In this case it fails to read the file, because it uses semicolons instead.

3. Next, we remove the `dec = ","` argument:

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", skip = 4)
str(vas)
```

`read.csv` reads the data without any error messages, but now `VAS` has become a `character` vector. By default, `read.csv` assumes that the file uses decimal points rather than decimals commas. When we don't specify that the file has decimal commas, `read.csv` interprets `0,4` as text rather than a number.

4. Next, we remove the `skip = 4` argument:

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", dec = ",")
str(vas)
names(vas)
```

`read.csv` looks for column names on the first row that it reads. `skip = 4` tells the function to skip the first 4 rows of the `.csv` file (which in this case were blank or contain other information about the data). When it doesn't skip those lines, the only text on the first row is `Data updated 2020-04-25`. This then becomes the name of the first column, and the remaining columns are named `X`, `X.1`, `X.2`, and so on.

5. Finally, we change `skip = 4` to `skip = 5`:

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", dec = ",", skip = 5)
str(vas)
names(vas)
```

In this case, `read.csv` skips the first 5 rows, which includes row 5, on which the variable names are given. It still looks for variable names on the first row that it reads though, meaning that the data values from the first observation become variable names instead of data points. An `X` is added at the beginning of the variable names, because variable names in R cannot begin with a number.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc4)

#### Exercise \@ref(exr:ch3exc5) {-#ch3solutions5}
1. First, set `file_path` to the path to `projects-email.xlsx`. Then we can use `read.xlsx` from the `openxlsx` package. The argument `sheet` lets us select which sheet to read:

```{r eval=FALSE}
library(openxlsx)
emails <- read.xlsx(file_path, sheet = 2)

View(emails)
str(emails)
```

2. To obtain a vector containing the email addresses without any duplicates, we apply `unique` to the vector containing the e-mail addresses. That vector is called `E-mail` with a hyphen `-`. We cannot access it using `emails$E-mail`, because R will interpret that as `email$E - mail`, and neither the vector `email$E` nor the variable `mail` exist. Instead, we can do one of the following:

```{r eval=FALSE}
unique(emails[,3])
unique(emails$"E-mail")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc5)

#### Exercise \@ref(exr:ch3exc6) {-#ch3solutions6}
1. We set `file_path` to the path to `vas-transposed.csv` and then read it:

```{r eval=FALSE}
vast <- read.csv(file_path)
dim(vast)
View(vast)
```

It is a data frame with 4 rows and 2366 variables.

2. Adding `row.names = 1` lets us read the row names:

```{r eval=FALSE}
vast <- read.csv(file_path, row.names = 1)
View(vast)
```

This data frame only contains 2365 variables, because the leftmost column is now the row names and not a variable.

3. `t` lets us rotate the data into the format that we are used to. If we only apply `t` though, the resulting object is a `matrix` and not a `data.frame`. If we want it to be a `data.frame`, we must also make a call to `as.data.frame`:

```{r eval=FALSE}
vas <- t(vast)
class(vas)

vas <- as.data.frame(t(vast))
class(vas)
```
`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc6)

#### Exercise \@ref(exr:ch3exc6bb) {-#ch3solutions6bb}
We fit the model and use `summary` to print estimates and p-values:

```{r eval=FALSE}
m <- lm(mpg ~ hp + wt + cyl + am, data = mtcars)
summary(m)
```

`hp` and `wt` are significant at the 5 % level, but `cyl` and `am` are not.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc6bb)



#### Exercise \@ref(exr:ch3exc8) {-#ch3solutions8}
We set `file_path` to the path for `vas.csv` and read the data as in Exercise \@ref(exr:ch3exc4)::

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", dec = ",", skip = 4)
```

1. First, we compute the mean VAS for each patient:
  
```{r eval=FALSE}
aggregate(VAS ~ ID, data = vas, FUN = mean)
```

2. Next, we compute the lowest and highest VAS recorded for each patient:

```{r eval=FALSE}
aggregate(VAS ~ ID, data = vas, FUN = min)
aggregate(VAS ~ ID, data = vas, FUN = max)
```

3. Finally, we compute the number of high-VAS days for each patient. One way to do this is to create a `logical` vector by `VAS >= 7` and then compute its sum.

```{r eval=FALSE}
aggregate((VAS >= 7) ~ ID, data = vas, FUN = sum)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc8)

#### Exercise \@ref(exr:ch3exc9) {-#ch3solutions9}
First we load and inspect the data:
```{r, eval=F}
library(datasauRus)
View(datasaurus_dozen)
```

1. Next, we compute summary statistics grouped by `dataset`:

```{r eval=FALSE}
aggregate(cbind(x, y) ~ dataset, data = datasaurus_dozen, FUN = mean)
aggregate(cbind(x, y) ~ dataset, data = datasaurus_dozen, FUN = sd)

by(datasaurus_dozen[, 2:3], datasaurus_dozen$dataset, cor)
```

The summary statistics for all datasets are virtually identical.
  
2. Next, we make scatterplots. Here is a solution using `ggplot2`:

```{r, eval=F}
library(ggplot2)
ggplot(datasaurus_dozen, aes(x, y, colour = dataset)) +
    geom_point() +
    facet_wrap(~ dataset, ncol = 3)
```

Clearly, the datasets are _very_ different! This is a great example of how simply computing summary statistics is not enough. They tell a part of the story, yes, but only a part.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc9)

#### Exercise \@ref(exr:ch3exc10) {-#ch3solutions10}
First, we load the `magrittr` package and create `x`:

```{r eval=FALSE}
library(magrittr)
x <- 1:8
```

1. `sqrt(mean(x))` can be rewritten as:

```{r eval=FALSE}
x %>% mean %>% sqrt
```

2. `mean(sqrt(x))` can be rewritten as:

```{r eval=FALSE}
x %>% sqrt %>% mean
```

3. `sort(x^2-5)[1:2]` can be rewritten as:

```{r eval=FALSE}
x %>% raise_to_power(2) %>% subtract(5) %>% extract(1:2,)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc10)

#### Exercise \@ref(exr:ch3exc11) {-#ch3solutions11}
We can use `inset` to add the new variable:

```{r eval=FALSE}
age <- c(28, 48, 47, 71, 22, 80, 48, 30, 31)
purchase <- c(20, 59, 2, 12, 22, 160, 34, 34, 29)
visit_length <- c(5, 2, 20, 22, 12, 31, 9, 10, 11)
bookstore <- data.frame(age, purchase, visit_length)

library(magrittr)
bookstore %>% inset("rev_per_minute",
                    value = .$purchase / .$visit_length)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch3exc11)

## Chapter 4 {-#solutionsch4}

#### Exercise \@ref(exr:ch4exc0) {-#ch4solutions0}
1. We change the background colour of the the entire plot to `lightblue`.

```{r eval=FALSE}
p + theme(panel.background = element_rect(fill = "lightblue"),
          plot.background = element_rect(fill = "lightblue"))
```

2. Next, we change the font of the legend to `serif`.

```{r eval=FALSE}
p + theme(panel.background = element_rect(fill = "lightblue"),
          plot.background = element_rect(fill = "lightblue"),
          legend.text = element_text(family = "serif"),
          legend.title = element_text(family = "serif"))
```

3. We remove the grid:

```{r eval=FALSE}
p + theme(panel.background = element_rect(fill = "lightblue"),
          plot.background = element_rect(fill = "lightblue"),
          legend.text = element_text(family = "serif"),
          legend.title = element_text(family = "serif"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
```

4. Finally, we change the colour of the axis ticks to `orange` and increase their width:

```{r eval=FALSE}
p + theme(panel.background = element_rect(fill = "lightblue"),
          plot.background = element_rect(fill = "lightblue"),
          legend.text = element_text(family = "serif"),
          legend.title = element_text(family = "serif"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.ticks = element_line(colour = "orange", size = 2))
```

It doesn't look all that great, does it? Let's just stick to the default theme in the remaining examples.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc0)


#### Exercise \@ref(exr:ch4exc9) {-#ch4solutions9}
1. We can use the `bw` argument to control the smoothness of the curves:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, colour = cut)) +
      geom_density(bw = 0.2)
```

2. We can fill the areas under the density curves by adding `fill` to the `aes`:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, colour = cut, fill = cut)) +
      geom_density(bw = 0.2)
```

3. Because the densities overlap, it'd be better to make the fill colours slightly transparent. We add `alpha` to the geom:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, colour = cut, fill = cut)) +
      geom_density(bw = 0.2, alpha = 0.2)
```

4. A similar plot can be created using `geom_density_ridges` from the `ggridges` package. Note that you must set `y = cut` in the `aes`, because the densities should be separated by cut.

```{r eval=FALSE}
install.packages("ggridges")
library(ggridges)

ggplot(diamonds, aes(carat, cut, fill = cut)) +
      geom_density_ridges()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc9)

#### Exercise \@ref(exr:ch4exc10) {-#ch4solutions10}
We use `xlim` to set the boundaries of the x-axis and `bindwidth` to decrease the bin width:

```{r eval=FALSE}
ggplot(diamonds, aes(carat)) +
      geom_histogram(binwidth = 0.01) +
      xlim(0, 3)
```

It appears that carat values that are just above multiples of 0.25 are more common than other values. We'll explore that next.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc10)

#### Exercise \@ref(exr:ch4exc11) {-#ch4solutions11}
1. We set the colours using the `fill` aesthetic:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, price, fill = cut)) +
      geom_violin()
```

2. Next, we remove the legend:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, price, fill = cut)) +
      geom_violin() +
      theme(legend.position = "none")
```

3. We add boxplots by adding an additional `geom` to the plot. Increasing the width of the violins and decreasing the width of the boxplots creates a better figure. We also move the `fill = cut` aesthetic from `ggplot` to `geom_violin` so that the boxplots use the default colours instead of different colours for each category.

```{r eval=FALSE}
ggplot(diamonds, aes(cut, price)) +
      geom_violin(aes(fill = cut), width = 1.25) +
      geom_boxplot(width = 0.1, alpha = 0.5) +
      theme(legend.position = "none")
```

4. Finally, we can create a horizontal version of the figure in the same way we did for boxplots in Section \@ref(exr:ch2exc9): by adding `coord_flip()` to the plot:

```{r eval=FALSE}
ggplot(diamonds, aes(cut, price)) +
      geom_violin(aes(fill = cut), width = 1.25) +
      geom_boxplot(width = 0.1, alpha = 0.5) +
      theme(legend.position = "none") +
      coord_flip()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc11)

#### Exercise \@ref(exr:ch4exc12) {-#ch4solutions12}
We can create an interactive scatterplot using:

```{r eval=FALSE}
myPlot <- ggplot(diamonds, aes(x, y,
                 text = paste("Row:", rownames(diamonds)))) +
      geom_point()

ggplotly(myPlot)
```

There are outliers along the y-axis on rows 24,068 and 49,190. There are also some points for which $x=0$. Examples include rows 11,183 and 49,558. It isn't clear from the plot, but in total there are 8 such points, 7 of which have both $x=0$ and $y=0$. To view all such diamonds, you can use `filter(diamonds, x==0)`. These observations must be due to data errors, since diamonds can't have 0 width. The high $y$-values also seem suspicious - carat is a measure of diamond weight, and if these diamonds really were 10 times longer than others then we would probably expect them to have unusually high carat values as well (which they don't).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc12)

#### Exercise \@ref(exr:ch4exc13) {-#ch4solutions13}
The two outliers are the only observations for which $y>20$, so we use that as our condition:

```{r eval=FALSE}
ggplot(diamonds, aes(x, y)) +
      geom_point() +
      geom_text(aes(label = ifelse(y > 20, rownames(diamonds), "")),
                hjust = 1.1)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc13)

#### Exercise \@ref(exr:ch4exc14) {-#ch4solutions14}
```{r eval=FALSE}
# Create a copy of diamonds, then replace x-values greater than 9
# with NA:
diamonds2 <- diamonds
diamonds2[diamonds2$x > 9] <- NA

## Create the scatterplot
ggplot(diamonds2, aes(carat, price, colour = is.na(x))) +
      geom_point()
```

In this plot, we see that virtually all high carat diamonds have missing `x` values. This seems to indicate that there is a systematic pattern to the missing data (which of course is correct in this case!), and we should proceed with any analyses of `x` with caution.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc14)



#### Exercise \@ref(exr:ch4exc15) {-#ch4solutions15}
The code below is an example of what your analysis can look like, with some remarks as comments:

```{r eval=FALSE}
# Investigate missing data
colSums(is.na(flights2))
# Not too much missing data in this dataset!
View(flights2[is.na(flights2$air_time),])
# Flights with missing data tend to have several missing variables.

# Ridge plots to compare different carriers (boxplots, facetted
# histograms and violin plots could also be used)
library(ggridges)
ggplot(flights2, aes(arr_delay, carrier, fill = carrier)) +
      geom_density_ridges() +
      theme(legend.position = "none") +
      xlim(-50, 250)
# Some airlines (e.g. EV) appear to have a larger spread than others

ggplot(flights2, aes(dep_delay, carrier, fill = carrier)) +
      geom_density_ridges() +
      theme(legend.position = "none") +
      xlim(-15, 100)
# Some airlines (e.g. EV) appear to have a larger spread others

ggplot(flights2, aes(air_time, carrier, fill = carrier)) +
      geom_density_ridges() +
      theme(legend.position = "none")
# VX only do long-distance flights, whereas MQ, FL and 9E only do
# shorter flights

# Make scatterplots and label outliers with flight numbers
ggplot(flights2, aes(dep_delay, arr_delay, colour = carrier)) +
      geom_point() +
      geom_text(aes(label = ifelse(arr_delay > 300,
                            paste("Flight", flight), "")),
                vjust = 1.2, hjust = 1)

ggplot(flights2, aes(air_time, arr_delay, colour = carrier)) +
      geom_point() +
      geom_text(aes(label = ifelse(air_time > 400 | arr_delay > 300,
                                   paste("Flight", flight), "")),
                vjust = 1.2, hjust = 1)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc15)


#### Exercise \@ref(exr:ch4exc1) {-#ch4solutions1}
1. To decrease the smoothness of the line, we use the `span` argument in `geom_smooth`. The default is `geom_smooth(span = 0.75)`. Decreasing this values yields a very different fit:

```{r eval=FALSE}
ggplot(msleep, aes(brainwt, sleep_total)) + 
      geom_point() +
      geom_smooth(span = 0.25) +
      xlab("Brain weight (logarithmic scale)") +
      ylab("Total sleep time") +
      scale_x_log10()
```

More smoothing is probably preferable in this case. The relationship appears to be fairly weak, and appears to be roughly linear.

2. We can use the `method` argument in `geom_smooth` to fit a straight line using `lm` instead of LOESS:

```{r eval=FALSE}
ggplot(msleep, aes(brainwt, sleep_total)) + 
      geom_point() +
      geom_smooth(method = "lm") +
      xlab("Brain weight (logarithmic scale)") +
      ylab("Total sleep time") +
      scale_x_log10()
```

3. To remove the confidence interval from the plot, we set `se = FALSE` in `geom_smooth`:

```{r eval=FALSE}
ggplot(msleep, aes(brainwt, sleep_total)) + 
      geom_point() +
      geom_smooth(method = "lm", se = FALSE) +
      xlab("Brain weight (logarithmic scale)") +
      ylab("Total sleep time") +
      scale_x_log10()
```

4. Finally, we can change the colour of the smoothing line using the `colour` argument:

```{r eval=FALSE}
ggplot(msleep, aes(brainwt, sleep_total)) + 
      geom_point() +
      geom_smooth(method = "lm", se = FALSE, colour = "red") +
      xlab("Brain weight (logarithmic scale)") +
      ylab("Total sleep time") +
      scale_x_log10()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc1)

#### Exercise \@ref(exr:ch4exc2) {-#ch4solutions2}
1. Adding the `geom_smooth` geom with the default settings produces a trend line that does not capture seasonality:

```{r eval=FALSE}
autoplot(a10) +
      geom_smooth()
```

2. We can change the axes labels using `xlab` and `ylab`:

```{r eval=FALSE}
autoplot(a10) +
      geom_smooth() +
      xlab("Year") +
      ylab("Sales ($ million)")
```

3. `ggtitle` adds a title to the figure:

```{r eval=FALSE}
autoplot(a10) +
      geom_smooth() +
      xlab("Year") +
      ylab("Sales ($ million)") +
      ggtitle("Anti-diabetic drug sales in Australia")
```

4. The `colour` argument can be passed to `autoplot` to change the colour of the time series line:

```{r eval=FALSE}
autoplot(a10, colour = "red") +
      geom_smooth() +
      xlab("Year") +
      ylab("Sales ($ million)") +
      ggtitle("Anti-diabetic drug sales in Australia")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc2)

#### Exercise \@ref(exr:ch4exc3) {-#ch4solutions3}
1. The text can be added by using `annotate(geom = "text", ...)`. In order not to draw the text on top of the circle, you can shift the x-value of the text (the appropriate shift depends on the size of your plot window):

```{r eval=FALSE}
autoplot(gold) +
      annotate(geom = "point", x = spike_date, y = gold[spike_date], 
               size = 5, shape = 21, colour = "red",
               fill = "transparent") +
      annotate(geom = "text", x = spike_date - 100,
               y = gold[spike_date], 
               label = "Incorrect value!")
```

2. We can remove the erroneous value by replacing it with `NA` in the time series:

```{r eval=FALSE}
gold[spike_date] <- NA
autoplot(gold)
```

3. Finally, we can add a reference line using `geom_hline`:
```{r eval=FALSE}
autoplot(gold) +
      geom_hline(yintercept = 400, colour = "red")
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc3)

#### Exercise \@ref(exr:ch4exc4) {-#ch4solutions4}
1. We can specify which variables to include in the plot as follows:

```{r eval=FALSE}
autoplot(elecdaily[, c("Demand", "Temperature")], facets = TRUE)
```

This produces a terrible-looking label for the y-axis, which we can remove by setting the y-label to `NULL`:

```{r eval=FALSE}
autoplot(elecdaily[, c("Demand", "Temperature")], facets = TRUE) +
      ylab(NULL)
```

2. As before, we can add smoothers using `geom_smooth`:
```{r eval=FALSE}
autoplot(elecdaily[, c("Demand", "Temperature")], facets = TRUE) +
      geom_smooth() +
      ylab(NULL)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc4)

#### Exercise \@ref(exr:ch4exc5) {-#ch4solutions5}
1. We set the size of the points using `geom_point(size)`:

```{r eval=FALSE}
ggplot(elecdaily2, aes(Temperature, Demand, colour = day)) +
      geom_point(size = 0.5) +
      geom_path()
```

2. To add annotations, we use `annotate` and some code to find the days of the lowest and highest temperatures:

```{r eval=FALSE}
## Lowest temperature
lowest <- which.min(elecdaily2$Temperature)

## Highest temperature
highest <- which.max(elecdaily2$Temperature)

## We shift the y-values of the text so that it appears above
# the points
ggplot(elecdaily2, aes(Temperature, Demand, colour = day)) +
      geom_point(size = 0.5) +
      geom_path() +
      annotate(geom = "text", x = elecdaily2$Temperature[lowest],
               y = elecdaily2$Demand[lowest] + 4, 
               label = elecdaily2$day[lowest]) +
      annotate(geom = "text", x = elecdaily2$Temperature[highest],
               y = elecdaily2$Demand[highest] + 4, 
               label = elecdaily2$day[highest])
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc5)

#### Exercise \@ref(exr:ch4exc6) {-#ch4solutions6}
We can specify `aes(group)` _for a particular geom only_ as follows:

```{r eval=FALSE}
ggplot(Oxboys, aes(age, height, colour = Subject)) + 
      geom_point() + 
      geom_line(aes(group = Subject)) +
      geom_smooth(method = "lm", colour = "red", se = FALSE)
```

`Subject` is now used for grouping the points used to draw the lines (i.e. for `geom_line`), but not for `geom_smooth`, which now uses all the points to create a trend line showing the average height of the boys over time.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc6)


#### Exercise \@ref(exr:ch4exc7) {-#ch4solutions7}
Code for producing the three plots is given below:

```{r eval=FALSE}
library(fma)

# Time series plot
autoplot(writing) +
      geom_smooth() +
      ylab("Sales (francs)") +
      ggtitle("Sales of printing and writing paper")

# Seasonal plot
ggseasonplot(writing, year.labels = TRUE, year.labels.left = TRUE) +
      ylab("Sales (francs)") +
      ggtitle("Seasonal plot of sales of printing and writing paper")
# There is a huge dip in sales in August, when many French offices are
# closed due to holidays.

# stl-decomposition
autoplot(stl(writing, s.window = 365)) +
      ggtitle("Seasonal decomposition of paper sales time series")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc7)

#### Exercise \@ref(exr:ch4exc75) {-#ch4solutions75}
We use the `cpt.var` functions with the default settings:

```{r eval=FALSE}
library(forecast)
library(fpp2)
library(changepoint)
library(ggfortify)

# Plot the time series:
autoplot(elecdaily[,"Demand"])

# Plot points where there are changes in the variance:
autoplot(cpt.var(elecdaily[,"Demand"]))
```

The variance is greater in the beginning of the year, and then appears to be more or less constant. Perhaps this can be explained by temperature?

```{r eval=FALSE}
# Plot the time series:
autoplot(elecdaily[,"Temperature"])
```

We see that the high-variance period coincides with peaks and large oscillations in temperature, which would cause the energy demand to increase and decrease more than usual, making the variance greater.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc75)

#### Exercise \@ref(exr:ch4exc75b) {-#ch4solutions75b}
By adding a copy of the observation for month 12, with the `Month` value replaced by 0, we can connect the endpoints to form a continuous curve:

```{r eval=FALSE}
Cape_Town_weather[13,] <- Cape_Town_weather[12,]
Cape_Town_weather$Month[13] <- 0

ggplot(Cape_Town_weather, aes(Month, Temp_C)) +
      geom_line() +
      coord_polar() +
      xlim(0, 12)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc75b)


#### Exercise \@ref(exr:ch4exc16) {-#ch4solutions16}
As for all `ggplot2` plots, we can use `ggtitle` to add a title to the plot:

```{r eval=FALSE}
ggpairs(diamonds[, which(sapply(diamonds, class) == "numeric")],
        aes(colour = diamonds$cut, alpha = 0.5)) +
      ggtitle("Numeric variables in the diamonds dataset")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc16)

#### Exercise \@ref(exr:ch4exc17) {-#ch4solutions17}
1. We create the correlogram using `ggcorr` as follows:

```{r eval=FALSE}
ggcorr(diamonds[, which(sapply(diamonds, class) == "numeric")])
```

2. `method` allows us to control which correlation coefficient to use:

```{r eval=FALSE}
ggcorr(diamonds[, which(sapply(diamonds, class) == "numeric")],
       method = c("pairwise", "spearman"))
```

3. `nbreaks` is used to create a categorical colour scale:

```{r eval=FALSE}
ggcorr(diamonds[, which(sapply(diamonds, class) == "numeric")],
       method = c("pairwise", "spearman"),
       nbreaks = 5)
```

4. `low` and `high` can be used to control the colours at the endpoints of the scale:

```{r eval=FALSE}
ggcorr(diamonds[, which(sapply(diamonds, class) == "numeric")],
       method = c("pairwise", "spearman"),
       nbreaks = 5,
       low = "yellow", high = "black")
```

(Yes, the default colours are a better choice!)

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc17)

#### Exercise \@ref(exr:ch4exc18) {-#ch4solutions18}
1. We replace `colour = vore` in the `aes` by `fill = vore` and add `colour = "black", shape = 21` to `geom_point`. The points now get black borders, which makes them a bit sharper:

```{r eval=FALSE}
ggplot(msleep, aes(brainwt, sleep_total, fill = vore, size = bodywt)) +
      geom_point(alpha = 0.5, colour = "black", shape = 21) +
      xlab("log(Brain weight)") +
      ylab("Sleep total (h)") +
      scale_x_log10() +
      scale_size(range = c(1, 20), trans = "sqrt",
                 name = "Square root of\nbody weight") +
      scale_color_discrete(name = "Feeding behaviour")
```

2. We can use `ggplotly` to create an interactive version of the plot. Adding `text` to the `aes` allows us to include more information when hovering points:

```{r eval=FALSE}
library(plotly)
myPlot <- ggplot(msleep, aes(brainwt, sleep_total, fill = vore,
                             size = bodywt, text = name)) +
      geom_point(alpha = 0.5, colour = "black", shape = 21) +
      xlab("log(Brain weight)") +
      ylab("Sleep total (h)") +
      scale_x_log10() +
      scale_size(range = c(1, 20), trans = "sqrt",
                 name = "Square root of\nbody weight") +
      scale_color_discrete(name = "Feeding behaviour")

ggplotly(myPlot)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc18)

#### Exercise \@ref(exr:ch4exc19) {-#ch4solutions19}
1. We create the tile plot using `geom_tile`. By setting `fun = max` we obtain the highest price in each bin:

```{r eval=FALSE}
ggplot(diamonds, aes(table, depth, z = price)) +
      geom_tile(binwidth = 1, stat = "summary_2d", fun = max) +
      ggtitle("Highest prices for diamonds with different depths
              and tables")
```

2. We can create the bin plot using either `geom_bin2d` or `geom_hex`:

```{r eval=FALSE}
ggplot(diamonds, aes(carat, price)) +
      geom_bin2d(bins = 50)
```

Diamonds with carat around 0.3 and price around 1000 have the highest bin counts.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc19)

#### Exercise \@ref(exr:ch4exc20) {-#ch4solutions20}
1. VS2 and Ideal is the most common combination:

```{r eval=FALSE}
diamonds2 <- aggregate(carat ~ cut + clarity, data = diamonds,
                       FUN = length)
names(diamonds2)[3] <- "Count"
ggplot(diamonds2, aes(clarity, cut, fill = Count)) +
      geom_tile()
```

2. As for continuous variables, we can use `geom_tile` with the arguments `stat = "summary_2d", fun = mean` to display the average prices for different combinations. SI2 and Premium is the combination with the highest average price:

```{r eval=FALSE}
ggplot(diamonds, aes(clarity, cut, z = price)) +
      geom_tile(binwidth = 1, stat = "summary_2d", fun = mean) +
      ggtitle("Mean prices for diamonds with different
              clarities and cuts")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc20)

#### Exercise \@ref(exr:ch4exc21) {-#ch4solutions21}
1. We create the scatterplot using:

```{r eval=FALSE}
library(gapminder)
library(GGally)

gapminder2007 <- gapminder[gapminder$year == 2007,]

ggpairs(gapminder2007[, c("lifeExp", "pop", "gdpPercap")],
        aes(colour = gapminder2007$continent, alpha = 0.5),
        upper = list(continuous = "na"))
```

2. The interactive facetted bubble plot is created using:

```{r eval=FALSE}
library(plotly)

gapminder2007 <- gapminder[gapminder$year == 2007,]

myPlot <- ggplot(gapminder2007, aes(gdpPercap, lifeExp, size = pop,
                                    colour = country)) +
      geom_point(alpha = 0.5) +
      scale_x_log10() +
      scale_size(range = c(2, 15)) +
      scale_colour_manual(values = country_colors) +
      theme(legend.position = "none") +
      facet_wrap(~ continent)

ggplotly(myPlot)
```

Well done, you just visualised 5 variables in a facetted bubble plot!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc21)

#### Exercise \@ref(exr:ch4exc22) {-#ch4solutions22}
1. Fixed wing multi engine Boeings are the most common planes:

```{r eval=FALSE}
library(nycflights13)
library(ggplot2)

planes2 <- aggregate(tailnum ~ type + manufacturer, data = planes,
                       FUN = length)

ggplot(planes2, aes(type, manufacturer, fill = tailnum)) +
      geom_tile()
```

2. The fixed wing multi engine Airbus has the highest average number of seats:

```{r eval=FALSE}
ggplot(planes, aes(type, manufacturer, z = seats)) +
      geom_tile(binwidth = 1, stat = "summary_2d", fun = mean) +
      ggtitle("Number of seats for different planes")
```

3. The number of seats seems to have increased in the 1980's, and then reached a plateau: 

```{r eval=FALSE}
ggplot(planes, aes(year, seats)) +
      geom_point(aes(colour = engine)) +
      geom_smooth()
```

The plane with the largest number of seats is not an Airbus, but a Boeing 747-451. It can be found using `planes[which.max(planes$seats),]` or visually using `plotly`:

```{r eval=FALSE}
myPlot <- ggplot(planes, aes(year, seats,
                             text = paste("Tail number:", tailnum,
                                          "<br>Manufacturer:",
                                          manufacturer))) +
      geom_point(aes(colour = engine)) +
      geom_smooth()

ggplotly(myPlot)
```

4. Finally, we can investigate what engines were used during different time periods in several ways, for instance by differentiating engines by colour in our previous plot:

```{r eval=FALSE}
ggplot(planes, aes(year, seats)) +
      geom_point(aes(colour = engine)) +
      geom_smooth()
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc22)


#### Exercise \@ref(exr:ch4exc23) {-#ch4solutions23}
First, we compute the principal components:

```{r eval=FALSE}
library(ggplot2)

# Compute principal components:
pca <- prcomp(diamonds[, which(sapply(diamonds, class) == "numeric")],
              center = TRUE, scale. = TRUE)
```

1. To see the proportion of variance explained by each component, we use `summary`:

```{r eval=FALSE}
summary(pca)
```

The first PC accounts for 65.5 % of the total variance. The first two account for 86.9 % and the first three account for 98.3 % of the total variance, meaning that 3 components are needed to account for at least 90 % of the total variance.
  
2. To see the loadings, we type:

```{r eval=FALSE}
pca
```

The first PC appears to measure size: it is dominated by `carat`, `x`, `y` and `z`, which all are size measurements. The second PC appears is dominated by `depth` and `table` and is therefore a summary of those measures.

3. To compute the correlation, we use `cor`:

```{r eval=FALSE}
cor(pca$x[,1], diamonds$price)
```
  
The (Pearson) correlation is 0.89, which is fairly high. Size is clearly correlated to price!
  
4. To see if the first two principal components be used to distinguish between diamonds with different cuts, we make a scatterplot:

```{r eval=FALSE}
autoplot(pca, data = diamonds, colour = "cut")
```

The points are mostly gathered in one large cloud. Apart from the fact that very large or very small values of the second PC indicates that a diamond has a Fair cut, the first two principal components seem to offer little information about a diamond's cut.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc23)


#### Exercise \@ref(exr:ch4exc24) {-#ch4solutions24}
We create the scatterplot with the added arguments:

```{r eval=FALSE}
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)

pca <- prcomp(seeds[,-8], center = TRUE, scale. = TRUE)

library(ggfortify)
autoplot(pca, data = seeds, colour = "Variety",
         loadings = TRUE, loadings.label = TRUE)
```

The arrows for `Area`, `Perimeter`, `Kernel_length`, `Kernel_width` and `Groove_length` are all about the same length and are close to parallel the x-axis, which shows that these have similar impact on the first principal component but not the second, making the first component a measure of size. `Asymmetry` and `Compactness` both affect the second component, making it a measure of shape. `Compactness` also affects the first component, but not as much as the size variables do.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc24)


#### Exercise \@ref(exr:ch4exc25) {-#ch4solutions25}
We change the `hc_method` and `hc_metric` arguments to use complete linkage and the Manhattan distance:

```{r eval=FALSE}
library(cluster)
library(factoextra)
votes.repub %>% scale() %>%
                hcut(k = 5, hc_func = "agnes",
                     hc_method = "complete",
                     hc_metric = "manhattan") %>% 
                fviz_dend()
```

`fviz_dend` produces `ggplot2` plots. We can save the plots from both approaches and then plot them side-by-side using `patchwork` as in Section \@ref(patchwork):

```{r eval=FALSE}
votes.repub %>% scale() %>%
                hcut(k = 5, hc_func = "agnes",
                     hc_method = "average",
                     hc_metric = "euclidean") %>% 
                fviz_dend() -> dendro1
votes.repub %>% scale() %>%
                hcut(k = 5, hc_func = "agnes",
                     hc_method = "complete",
                     hc_metric = "manhattan") %>% 
                fviz_dend() -> dendro2

library(patchwork)
dendro1 / dendro2
```

Alaska and Vermont are clustered together in both cases. The red leftmost cluster is similar but not identical, including Alabama, Georgia and Louisiana.

To compare the two dendrograms in a different way, we can use `tanglegram`. Setting `k_labels = 5` and `k_branches = 5` gives us 5 coloured clusters:

```{r eval=FALSE}
votes.repub %>% scale() %>%
                hcut(k = 5, hc_func = "agnes",
                     hc_method = "average",
                     hc_metric = "euclidean") -> clust1
votes.repub %>% scale() %>%
                hcut(k = 5, hc_func = "agnes",
                     hc_method = "complete",
                     hc_metric = "manhattan") -> clust2

library(dendextend)
tanglegram(as.dendrogram(clust1), 
           as.dendrogram(clust2),
           k_labels = 5,
           k_branches = 5)
```

Note that the colours of the lines connecting the two dendrograms are unrelated to the colours of the clusters.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc25)

#### Exercise \@ref(exr:ch4exc25b) {-#ch4solutions25b}
Using the default settings in `agnes`, we can do the clustering using:

```{r eval=FALSE}
library(cluster)
library(magrittr)
USArrests %>% scale() %>%
                agnes() %>% 
                plot(which = 2)
```

Maryland is clustered with New Mexico, Michigan and Arizona, in that order.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc25b)


#### Exercise \@ref(exr:ch4exc25c) {-#ch4solutions25c}
We draw a heatmap, with the data standardised in the column direction because we wish to cluster the observations rather than the variables:

```{r eval=FALSE}
library(cluster)
library(magrittr)
USArrests %>% as.matrix() %>% heatmap(scale = "col")
```

You may want to increase the height of your Plot window so that the names of all states are displayed properly.

The heatmap shows that Maryland, and the states similar to it, has higher crime rates than most other states. There are a few other states with high crime rates in other clusters, but those tend to only have a high rate for one crime (e.g. Georgia, which has a very high murder rate), whereas states in the cluster that Maryland is in have high rates for all or almost all types of violent crime.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc25c)

#### Exercise \@ref(exr:ch4exc26) {-#ch4solutions26}
First, we inspect the data:

```{r eval=FALSE}
library(cluster)
?chorSub

# Scatterplot matrix:
library(GGally)
ggpairs(chorSub)
```

There are a few outliers, so it may be a good idea to use `pam` as it is less affected by outliers than `kmeans`. Next, we draw some plots to help use choose $k$:

```{r eval=FALSE}
library(factoextra)
library(magrittr)
chorSub %>% scale() %>% 
                fviz_nbclust(pam, method = "wss")
chorSub %>% scale() %>% 
                fviz_nbclust(pam, method = "silhouette")
chorSub %>% scale() %>% 
                fviz_nbclust(pam, method = "gap")
```

There is no pronounced elbow in the WSS plot, although slight changes appear to occur at $k=3$ and $k=7$. Judging by the silhouette plot, $k=3$ may be a good choice, while the gap statistic indicates that $k=7$ would be preferable. Let's try both values:

```{r eval=FALSE}
# k = 3:
chorSub %>% scale() %>% 
                pam(k = 3) -> kola_cluster
fviz_cluster(kola_cluster, geom = "point")

# k = 7:
chorSub %>% scale() %>% 
                pam(k = 7) -> kola_cluster
fviz_cluster(kola_cluster, geom = "point")
```

Neither choice is clearly superior. Remember that clustering is an exploratory procedure, that we use to try to better understand our data.

The plot for $k=7$ may look a little strange, with two largely overlapping clusters. Bear in mind though, that the clustering algorithm uses all 10 variables and not just the first two principal components, which are what is shown in the plot. The differences between the two clusters isn't captured by the first two principal components.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc26)

#### Exercise \@ref(exr:ch4exc27) {-#ch4solutions27}
First, we try to find a good number of clusters:

```{r eval=FALSE}
library(factoextra)
library(magrittr)
USArrests %>% scale() %>% 
                fviz_nbclust(fanny, method = "wss")
USArrests %>% scale() %>% 
                fviz_nbclust(fanny, method = "silhouette")
```

We'll go with $k=2$ clusters:

```{r eval=FALSE}
library(cluster)
USArrests %>% scale() %>%
                fanny(k = 2) -> USAclusters

# Show memberships:
USAclusters$membership
```

Maryland is mostly associated with the first cluster. Its neighbouring state New Jersey is equally associated with both clusters.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc27)

#### Exercise \@ref(exr:ch4exc28) {-#ch4solutions28}
We do the clustering and plot the resulting clusters:

```{r eval=FALSE}
library(cluster)
library(mclust)
kola_cluster <- Mclust(scale(chorSub))
summary(kola_cluster)

# Plot results with ellipsoids:
library(factoextra)
fviz_cluster(kola_cluster, geom = "point", ellipse.type = "norm")
```

Three clusters, that overlap substantially when the first two principal components are plotted, are found.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc28)


#### Exercise \@ref(exr:ch4exc29) {-#ch4solutions29}
First, we have a look at the data:

```{r eval=FALSE}
?ability.cov
ability.cov
```

We can imagine several different latent variables that could explain how well the participants performed in these tests: general ability, visual ability, verbal ability, and so on. Let's use a scree plot to determine how many factors to use:

```{r eval=FALSE}
library(psych)
scree(ability.cov$cov, pc = FALSE)
```

2 or 3 factors seem like a good choice here. Let's try both:

```{r eval=FALSE}
# 2-factor model:
ab_fa2 <- fa(ability.cov$cov, nfactors = 2,
             rotate = "oblimin", fm = "ml")
fa.diagram(ab_fa2, simple = FALSE)

# 3-factor model:
ab_fa3 <- fa(ability.cov$cov, nfactors = 3,
             rotate = "oblimin", fm = "ml")
fa.diagram(ab_fa3, simple = FALSE)
```

In the 2-factor model, one factor is primarily associated with the visual variables (which we interpret as the factor describing visual ability), whereas the other primarily is associated with reading and vocabulary (verbal ability). Both are associated with the measure of general intelligence.

In the 3-factor model, there is still a factor associated with reading and vocabulary. There are two factors associated with the visual tests: one with block design and mazes and one with picture completion and general intelligence.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc29)

#### Exercise \@ref(exr:ch4exc30) {-#ch4solutions30}
First, we have a look at the data:

```{r eval=FALSE}
library(poLCA)
?cheating
View(cheating)
```

Next, we perform a latent class analysis with `GPA` as a covariate:

```{r eval=FALSE}
m <- poLCA(cbind(LIEEXAM, LIEPAPER,
                 FRAUD, COPYEXAM) ~ GPA,
           data = cheating, nclass = 2)
```

The two classes roughly correspond to cheaters and non-cheaters. From the table showing the relationship with `GPA`, we see students with high GPA's are less likely to be cheaters.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch4exc30)



## Chapter 5 {-#ch5solutions}

#### Exercise \@ref(exr:ch5exc1) {-#ch5solutions1}
1. `as.logical` returns `FALSE` for `0` and `TRUE` for all other numbers:
```{r eval=FALSE}
as.logical(0)
as.logical(1)
as.logical(14)
as.logical(-8.889)
as.logical(pi^2 + exp(18))
```

2. When the `as.` functions are applied to vectors, they convert all values in the vector:

```{r eval=FALSE}
as.character(c(1, 2, 3, pi, sqrt(2)))
```  
  
3. The `is.` functions return a `logical`: `TRUE` if the variable is of the type and `FALSE` otherwise:

```{r eval=FALSE}
is.numeric(27)
is.numeric("27")
is.numeric(TRUE)
``` 

4. The `is.` functions show that `NA` in fact is a (special type of) `logical`. This is also verified by the documentation for `NA`:

```{r eval=FALSE}
is.logical(NA)
is.numeric(NA)
is.character(NA)
?NA
``` 

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc1)

#### Exercise \@ref(exr:ch5exc1b) {-#ch5solutions1b}
We set `file_path` to the path for `vas.csv` and load the data as in Exercise \@ref(exr:ch3exc4):

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", dec = ",", skip = 4)
```

To split the `VAS` vector by patient ID, we use `split`:

```{r eval=FALSE}
vas_split <- split(vas$VAS, vas$ID)
```

To access the values for patient 212, either of the following works:

```{r eval=FALSE}
vas_split$`212`
vas_split[[12]]
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc1b)


#### Exercise \@ref(exr:ch5exc2) {-#ch5solutions2}
1. To convert the proportions to percentages with one decimal place, we must first multiply them by 100 and then round them:

```{r eval=FALSE}
props <- c(0.1010, 0.2546, 0.6009, 0.0400, 0.0035)
round(100 * props, 1)
``` 

2. The cumulative maxima and minima are computed using `cummax` and `cummin`:

```{r eval=FALSE}
cummax(airquality$Temp)
cummin(airquality$Temp)
```

The minimum during the period occurs on the 5th day, whereas the maximum occurs during day 120.

3. To find runs of days with temperatures above 80, we use `rle`:

```{r eval=FALSE}
runs <- rle(airquality$Temp > 80)
```

To find runs with temperatures above 80, we extract the length of the runs for which `runs$values` is `TRUE`:

```{r eval=FALSE}
runs$lengths[runs$values == TRUE]
```

We see that the longest run was 23 days.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc2)

#### Exercise \@ref(exr:ch5exc3) {-#ch5solutions3}
1. On virtually all systems, the largest number that R can represent as a floating point is `1.797693e+308`. You can find this by gradually trying larger and larger numbers:

```{r eval=FALSE}
1e+100
# ...
1e+308
1e+309  # The largest number must be between 1e+308 and 1e+309!
# ...
1.797693e+308
1.797694e+308
```

2. If we place the `^2` inside `sqrt` the result becomes 0:

```{r eval=FALSE}
sqrt(2)^2 - 2  # Not 0
sqrt(2^2) - 2  # 0
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc3)

#### Exercise \@ref(exr:ch5exc4) {-#ch5solutions4}
We re-use the solution from Exercise \@ref(exr:ch3exc3b):

```{r eval=FALSE}
airquality$TempCat <- cut(airquality$Temp,
                          breaks = c(50, 70, 90, 110))
```

1. Next, we change the levels' names:

```{r eval=FALSE}
levels(airquality$TempCat) <- c("Mild", "Moderate", "Hot")
```

2. Finally, we combine the last two levels:

```{r eval=FALSE}
levels(airquality$TempCat)[2:3] <- "Hot"
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc4)



#### Exercise \@ref(exr:ch5exc5) {-#ch5solutions5}
1 We start by converting the `vore` variable to a `factor`:

```{r eval=FALSE}
library(ggplot2)
str(msleep) # vore is a character vector!

msleep$vore <- factor(msleep$vore)
levels(msleep$vore)
```

The levels are ordered alphabetically, which is the default in R.

2. To compute grouped means, we use `aggregate`:

```{r eval=FALSE}
means <- aggregate(sleep_total ~ vore, data = msleep, FUN = mean)
```

3. Finally, we sort the factor levels according to their `sleep_total` means:

```{r eval=FALSE}
# Check order:
means
# New order: herbi, carni, omni, insecti.

# We could set the new order manually:
msleep$vore <- factor(msleep$vore,
                      levels = c("herbi", "carni", "omni", "insecti"))

# Alternatively, rank and match can be used to get the new order of
# the levels:
?rank
?match
ranks <- rank(means$sleep_total)
new_order <- match(1:4, ranks)

msleep$vore <- factor(msleep$vore,
                      levels = levels(msleep$vore)[new_order])
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc5)

#### Exercise \@ref(exr:ch5exc6) {-#ch5solutions6}
First, we set `file_path` to the path to `handkerchiefs.csv` and import it to the data frame `pricelist`:

```{r eval=FALSE}
pricelist <- read.csv(file_path)
```

1. `nchar` counts the number of characters in strings:

```{r eval=FALSE}
?nchar
nchar(pricelist$Italian.handkerchiefs)
```

2. We can use `grep` and a regular expression to see that there are 2 rows of the `Italian.handkerchief` column that contain numbers:

```{r eval=FALSE}
grep("[[:digit:]]", pricelist$Italian.handkerchiefs)
```

3. To extract the prices in shillings (S) and pence (D) from the `Price` column and store these in two new `numeric` variables in our data frame, we use `strsplit`, `unlist` and `matrix` as follows:
  
```{r eval=FALSE}
# Split strings at the space between the numbers and the letters:
Price_split <- strsplit(pricelist$Price, " ")
Price_split <- unlist(Price_split)
Price_matrix <- matrix(Price_split, nrow = length(Price_split)/4,
                       ncol = 4, byrow = TRUE)

# Add to the data frame:
pricelist$PriceS <- as.numeric(Price_matrix[,1])
pricelist$PriceD <- as.numeric(Price_matrix[,3])
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc6)


#### Exercise \@ref(exr:ch5exc65) {-#ch5solutions65}
We set `file_path` to the path to `oslo-biomarkers.xlsx` and load the data:

```{r, eval=F}
library(openxlsx)

oslo <- as.data.table(read.xlsx(file_path))
```

To find out how many patients were included in the study, we use `strsplit` to split the ID-timepoint string, and then `unique`:

```{r, eval=F}
oslo_id <- unlist(strsplit(oslo$"PatientID.timepoint", "-"))

oslo_id_matrix <- matrix(oslo_id, nrow = length(oslo_id)/2,
                         ncol = 2, byrow = TRUE)

unique(oslo_id_matrix[,1])
length(unique(oslo_id_matrix[,1]))
```

We see that 118 patients were included in the study.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc65)

#### Exercise \@ref(exr:ch5exc7) {-#ch5solutions7}
1. `"$g"` matches strings ending with `g`:

```{r eval=FALSE}
contacts$Address[grep("g$", contacts$Address)]
```

2. `"^[^[[:digit:]]"` matches strings beginning with anything but a digit: 

```{r eval=FALSE}
contacts$Address[grep("^[^[[:digit:]]", contacts$Address)]
```

3. `"a(s|l)"` matches strings containing either `as` or `al`:

```{r eval=FALSE}
contacts$Address[grep("a(s|l)", contacts$Address)]
```

4. `"[[:lower:]]+[.][[:lower:]]+"` matches strings containing any number of lowercase letters, followed by a period `.`, followed by any number of lowercase letters:

```{r eval=FALSE}
contacts$Address[grep("[[:lower:]]+[.][[:lower:]]+", contacts$Address)]
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc7)

#### Exercise \@ref(exr:ch5exc7b) {-#ch5solutions7b}
We want to extract all words, i.e. segments of characters separated by white spaces. First, let's create the string containing example sentences:

```{r eval=FALSE}
x <- "This is an example of a sentence, with 10 words. Here are 4 more!"
```

Next, we split the string at the spaces:

```{r eval=FALSE}
x_split <- strsplit(x, " ")
```

Note that `x_split` is a `list`. To turn this into a vector, we use `unlist`

```{r eval=FALSE}
x_split <- unlist(x_split)
```

Finally, we can use `gsub` to remove the punctuation marks, so that only the words remain:

```{r eval=FALSE}
gsub("[[:punct:]]", "", x_split)
```

If you like, you can put all steps on a single row:

```{r eval=FALSE}
gsub("[[:punct:]]", "", unlist(strsplit(x, " ")))
```

...or reverse the order of the operations:

```{r eval=FALSE}
unlist(strsplit(gsub("[[:punct:]]", "", x), " "))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc7b)




#### Exercise \@ref(exr:ch5exc75) {-#ch5solutions75}
1. The functions are used to extract the weekday, month and quarter for each date:
```{r eval=FALSE}
weekdays(dates)
months(dates)
quarters(dates)
```

2. `julian` can be used to compute the number of days from a specific date (e.g. 1970-01-01) to each date in the vector:

```{r eval=FALSE}
julian(dates, origin = as.Date("1970-01-01", format = "%Y-%m-%d"))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc75)

#### Exercise \@ref(exr:ch5exc8) {-#ch5solutions8}
1. On most systems, converting the three variables to `Date` objects using `as.Date` yields correct dates _without times_:

```{r eval=FALSE}
as.Date(c(time1, time2, time3))
```

2. We convert `time1` to a `Date` object and add `1` to it:

```{r eval=FALSE}
as.Date(time1) + 1
```

The result is `2020-04-02`, i.e. adding `1` to the `Date` object has added 1 day to it.

3. We convert `time3` and `time1` to `Date` objects and subtract them:

```{r eval=FALSE}
as.Date(time3) - as.Date(time1)
```

The result is a `difftime` object, printed as `Time difference of 2 days`. Note that the times are ignored, just as before.

4. We convert `time2` and `time1` to `Date` objects and subtract them:

```{r eval=FALSE}
as.Date(time2) - as.Date(time1)
```

The result is printed as `Time difference of 0 days`, because the difference in time is ignored.

5. We convert the three variables to `POSIXct` date and time objects using `as.POSIXct` without specifying the date format:

```{r eval=FALSE}
as.POSIXct(c(time1, time2, time3))
```

On most systems, this yields correctly displayed dates _and_ times.

6. We convert `time3` and `time1` to `POSIXct` objects and subtract them:

```{r eval=FALSE}
as.POSIXct(time3) - as.POSIXct(time1)
```

This time out, time is included when the difference is computed, and the output is `Time difference of 2.234722 days`.

7. We convert `time2` and `time1` to `POSIXct` objects and subtract them:

```{r eval=FALSE}
as.POSIXct(time2) - as.POSIXct(time1)
```

In this case, the difference is presented in hours: `Time difference of 1.166667 hours`. In the next step, we take control over the units shown in the output.

8. `difftime` can be used to control what units are used for expressing differences between two timepoints:

```{r eval=FALSE}
difftime(as.POSIXct(time3), as.POSIXct(time1), units = "hours")
```

The out is `Time difference of 53.63333 hours`.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc8)

#### Exercise \@ref(exr:ch5exc8b) {-#ch5solutions8b}
1. Using the first option, the `Date` becomes the _first_ day of the quarter. Using the second option, it becomes the _last_ day of the quarter instead. Both can be useful for presentation purposes - which you prefer is a matter of taste.

2. To convert the quarter-observations to the first day of their respective quarters, we use `as.yearqtr` as follows:

```{r eval=FALSE}
library(zoo)
as.Date(as.yearqtr(qvec2, format = "Q%q/%y"))
as.Date(as.yearqtr(qvec3, format = "Q%q-%Y"))
```

`%q`, `%y`,and `%Y` are date tokens. The other letters and symbols in the `format` argument simply describe other characters included in the format.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc8b)

#### Exercise \@ref(exr:ch5exc9) {-#ch5solutions9}
The x-axis of the data can be changed in multiple ways. A simple approach is the following:
```{r eval=FALSE}
## Create a new data frame with the correct dates and the demand data:
dates <- seq.Date(as.Date("2014-01-01"), as.Date("2014-12-31"),
                  by = "day")
elecdaily2 <- data.frame(dates = dates, demand = elecdaily[,1])

ggplot(elecdaily2, aes(dates, demand)) +
      geom_line()
```

A more elegant approach relies on the `xts` package for time series:

```{r eval=FALSE}
library(xts)
## Convert time series to an xts object:
dates <- seq.Date(as.Date("2014-01-01"), as.Date("2014-12-31"),
                  by = "day")
elecdaily3 <- xts(elecdaily, order.by = dates)

autoplot(elecdaily3[,"Demand"])
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc9)


#### Exercise \@ref(exr:ch5exc10) {-#ch5solutions10}
```{r eval=FALSE}
## First, create a data frame with better formatted dates
a102 <- as.data.frame(a10)
a102$Date <- seq.Date(as.Date("1991-07-01"), as.Date("2008-06-01"),
                      by = "month")

## Create the plot object
myPlot <- ggplot(a102, aes(Date, x)) +
      geom_line() +
      xlab("Sales")
      
## Create the interactive plot
ggplotly(myPlot)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc10)



#### Exercise \@ref(exr:ch5exc11) {-#ch5solutions11}
We set `file_path` to the path for `vas.csv` and read the data as in Exercise \@ref(exr:ch3exc4) and convert it to a `data.table` (the last step being optional if we're only using `dplyr` for this exercise):

```{r eval=FALSE}
vas <- read.csv(file_path, sep = ";", dec = ",", skip = 4)
vas <- as.data.table(vas)
```

A better option is to achieve the same result in a single line by using the `fread` function from `data.table`:

```{r eval=FALSE}
vas <- fread(file_path, sep = ";", dec = ",", skip = 4)
```

1. First, we remove the columns `X` and `X.1`:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, c("X", "X.1") := NULL]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% select(-X, -X.1) -> vas
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Second, we add a dummy variable called `highVAS` that indicates whether a patient's `VAS` is 7 or greater on any given day:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, highVAS := VAS >= 7]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% mutate(highVAS = VAS >= 7) -> vas
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc11)

#### Exercise \@ref(exr:ch5exc14) {-#ch5solutions14}
We re-use the solution from Exercise \@ref(exr:ch3exc3b):

```{r eval=FALSE}
airquality$TempCat <- cut(airquality$Temp,
                          breaks = c(50, 70, 90, 110))

aq <- data.table(airquality)
```

1. Next, we change the levels' names:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
new_names = c("Mild", "Moderate",
              "Hot")
aq[.(TempCat = levels(TempCat),
         to = new_names),
       on = "TempCat",
       TempCat := i.to]
aq[,TempCat := droplevels(TempCat)]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
aq %>% mutate(TempCat = recode(TempCat,
              "(50,70]" = "Mild",
              "(70,90]" = "Moderate",
              "(90,110]" = "Hot")) -> aq
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Finally, we combine the last two levels:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
aq[.(TempCat = c("Moderate", "Hot"),
         to = "Hot"),
    on = "TempCat", TempCat := i.to]
aq[, TempCat := droplevels(TempCat)]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
aq %>% mutate(TempCat = recode(TempCat,
                  "Moderate" = "Hot"))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc14)

#### Exercise \@ref(exr:ch5exc12) {-#ch5solutions12}
We set `file_path` to the path for `vas.csv` and read the data as in Exercise \@ref(exr:ch3exc4) using `fread` to import it as a `data.table`:

```{r eval=FALSE}
vas <- fread(file_path, sep = ";", dec = ",", skip = 4)
```

1. First, we compute the mean VAS for each patient:
  
`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, mean(VAS, na.rm = TRUE), ID]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% group_by(ID) %>%
       summarise(meanVAS = 
          mean(VAS, na.rm = TRUE))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Next, we compute the lowest and highest VAS recorded for each patient:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, .(min = min(VAS,
                  na.rm = TRUE),
        max = max(VAS,
                  na.rm = TRUE)),
        ID]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% group_by(ID) %>%
       summarise(min = min(VAS,
                 na.rm = TRUE),
                 max = max(VAS,
                 na.rm = TRUE))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

3. Finally, we compute the number of high-VAS days for each patient. We can compute the sum directly:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, sum(VAS >= 7, na.rm = TRUE),
    ID]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% group_by(ID) %>%
       summarise(highVASdays = 
        sum(VAS >= 7, na.rm = TRUE))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

Alternatively, we can do this by first creating a dummy variable for high-VAS days:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, highVAS := VAS >=7]
vas[, sum(highVAS, na.rm = TRUE),
    ID]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
vas %>% mutate(highVAS = VAS >= 7) -> vas
vas %>% group_by(ID) %>%
       summarise(highVASdays = sum(highVAS,
                 na.rm = TRUE))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc12)

#### Exercise \@ref(exr:ch5exc13) {-#ch5solutions13}
First we load the data and convert it to a `data.table` (the last step being optional if we're only using `dplyr` for this exercise):
```{r, eval=F}
library(datasauRus)
dd <- as.data.table(datasaurus_dozen)
```

1. Next, we compute summary statistics grouped by `dataset`:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
dd[, .(mean_x = mean(x),
        mean_y = mean(y),
        sd_x = sd(x),
        sd_y = sd(y),
        cor = cor(x,y)),
        dataset]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
dd %>% group_by(dataset) %>%
       summarise(mean_x = mean(x),
        mean_y = mean(y),
        sd_x = sd(x),
        sd_y = sd(y),
        cor = cor(x,y))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

The summary statistics for all datasets are virtually identical.
  
2. Next, we make scatterplots. Here is a solution using `ggplot2`:

```{r, eval=F}
library(ggplot2)
ggplot(datasaurus_dozen, aes(x, y, colour = dataset)) +
    geom_point() +
    facet_wrap(~ dataset, ncol = 3)
```

Clearly, the datasets are _very_ different! This is a great example of how simply computing summary statistics is not enough. They tell a part of the story, yes, but only a part.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc13)

#### Exercise \@ref(exr:ch5exc13b) {-#ch5solutions13b}
We set `file_path` to the path for `vas.csv` and read the data as in Exercise \@ref(exr:ch3exc4) using `fread` to import it as a `data.table`:

```{r eval=FALSE}
library(data.table)
vas <- fread(file_path, sep = ";", dec = ",", skip = 4)
```

To fill in the missing values, we can now do as follows:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
vas[, Visit := nafill(
      Visit, "locf")]
```
`r if (knitr::is_html_output()) '</div><div class="column-right">'`\columnbreak
With `tidyr`:
```{r, eval=F}
vas %>% fill(Visit)
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc13b)



#### Exercise \@ref(exr:ch5exc15) {-#ch5solutions15}
We set `file_path` to the path to `ucdp-onesided-191.csv` and load the data as a `data.table` using `fread`:

```{r, eval=F}
library(dplyr)
library(data.table)

ucdp <- fread(file_path)
```

1. First, we filter the rows so that only conflicts that took place in Colombia are retained.

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
colombia <- ucdp[location ==
                   "Colombia",]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
ucdp %>% filter(location ==
         "Colombia") -> colombia
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

To list the number of different actors responsible for attacks, we can use `unique`:

```{r, eval=F}
unique(colombia$actor_name)
```

We see that there were attacks by 7 different actors during the period.

2. To find the number of fatalities caused by government attacks on civilians, we first filter the data to only retain rows where the actor name contains the word _government_:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
gov <- ucdp[actor_name %like%
              "[gG]overnment",]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
ucdp %>% filter(grepl("[gG]overnment",
                actor_name)
                ) -> gov
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

It may be of interest to list the governments involved in attacks on civilians:

```{r, eval=F}
unique(gov$actor_name)
```

To estimate the number of fatalities cause by these attacks, we sum the fatalities from each attack:

```{r, eval=F}
sum(gov$best_fatality_estimate)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc15)




#### Exercise \@ref(exr:ch5exc16) {-#ch5solutions16}
We set `file_path` to the path to `oslo-biomarkers.xlsx` and load the data:

```{r, eval=F}
library(dplyr)
library(data.table)
library(openxlsx)

oslo <- as.data.table(read.xlsx(file_path))
```

1. First, we select only the measurements from blood samples taken at 12 months. These are the only observations where the `PatientID.timepoint` column contains the word `months`:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo[PatientID.timepoint %like%
       "months",]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo %>% filter(grepl("months",
           PatientID.timepoint))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Second, we select only the measurements from the patient with ID number 6. Note that we cannot simply search for strings containing a `6`, as we then also would find measurements from other patients taken at 6 weeks, as well as patients with a 6 in their ID number, e.g. patient 126. Instead, we search for strings beginning with `6-`:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo[PatientID.timepoint %like%
       "^6[-]",]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo %>% filter(grepl("^6[-]",
           PatientID.timepoint))
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc16)

#### Exercise \@ref(exr:ch5exc17) {-#ch5solutions17}
We set `file_path` to the path to `ucdp-onesided-191.csv` and load the data as a `data.table` using `fread`:

```{r, eval=F}
library(dplyr)
library(data.table)

ucdp <- fread(file_path)
```

Next, we select the `actor_name`, `year`, `best_fatality_estimate` and `location` columns:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
ucdp[, .(actor_name, year,
         best_fatality_estimate,
         location)]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
ucdp %>% select(actor_name, year,
          best_fatality_estimate,
          location)
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc17)

#### Exercise \@ref(exr:ch5exc18) {-#ch5solutions18}
We set `file_path` to the path to `oslo-biomarkers.xlsx` and load the data:

```{r, eval=F}
library(dplyr)
library(data.table)
library(openxlsx)

oslo <- as.data.table(read.xlsx(file_path))
```

We then order the data by the `PatientID.timepoint` column:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo[order(PatientID.timepoint),]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo %>% arrange(PatientID.timepoint)
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

Note that because `PatientID.timepoint` is a `character` column, the rows are now ordered in _alphabetical_ order, meaning that patient 1 is followed by 100, 101, 102, and so on. To order the patients in _numerical_ order, we must first split the ID and timepoints into two different columns. We'll see how to do that in the next section, and try it out on the `oslo` data in Exercise \@ref(exr:ch5exc19).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc18)

#### Exercise \@ref(exr:ch5exc19) {-#ch5solutions19}
We set `file_path` to the path to `oslo-biomarkers.xlsx` and load the data:

```{r, eval=F}
library(dplyr)
library(tidyr)
library(data.table)
library(openxlsx)

oslo <- as.data.table(read.xlsx(file_path))
```

1. First, we split the `PatientID.timepoint` column:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo[, c("PatientID",
         "timepoint") :=
  tstrsplit(PatientID.timepoint, "-",
                 fixed = TRUE)]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `tidyr`:
```{r, eval=F}
oslo %>% separate(PatientID.timepoint,
           into = c("PatientID",
                   "timepoint"),
           sep = "-") -> oslo
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Next, we reformat the patient ID to a `numeric` and sort the table:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo[, PatientID :=
       as.numeric(PatientID)]
oslo[order(PatientID),]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo %>% mutate(PatientID =
          as.numeric(PatientID)) %>% 
          arrange(PatientID)
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

3. Finally, we reformat the data from long to wide, keeping the IL-8 and VEGF-A measurements. We store it as oslo2, knowing that we'll need it again in Exercise \@ref(exr:ch5exc20).

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
oslo2 <- dcast(oslo,
          PatientID ~ timepoint,
          value.var = c("IL-8", "VEGF-A"))
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `tidyr`:
```{r, eval=F}
oslo %>% pivot_wider(id_cols =
                        PatientID,
           names_from = timepoint,
           values_from = 
             c("IL-8", "VEGF-A")
           ) -> oslo2
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc19)

#### Exercise \@ref(exr:ch5exc20) {-#ch5solutions20}
We use the `oslo2` data frame that [we created in Exercise \@ref(exr:ch5exc20)](#ch5solutions19). In addition, we set `file_path` to the path to `oslo-covariates.xlsx` and load the data:

```{r, eval=F}
library(dplyr)
library(data.table)
library(openxlsx)

covar <- as.data.table(read.xlsx(file_path))
```

1. First, we merge the wide data frame from Exercise \@ref(exr:ch5exc19) with the `oslo-covariates.xlsx` data, using patient ID as key. A left join, where we only keep data for patients with biomarker measurements, seems appropriate here. We see that both datasets have a column named `PatientID`, which we can use as our key.

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
merge(oslo2, covar, 
      all.x = TRUE,
      by = "PatientID")
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo2 %>% left_join(covar,
           by = "PatientID")
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

2. Next, we use the `oslo-covariates.xlsx` data to select data for smokers from the wide data frame using a semijoin. The `Smoker.(1=yes,.2=no)` column contains information about smoking habits. First we create a table for filtering:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
filter_data <-
  covar[`Smoker.(1=yes,.2=no)`
                     == 1,]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
covar %>%
  filter(`Smoker.(1=yes,.2=no)`
          == 1) -> filter_data
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

Next, we perform the semijoin:

`r if (knitr::is_html_output()) '<table><div class="column-left">'`\btwocol
With `data.table`:
```{r eval=FALSE}
setkey(oslo2, PatientID)
oslo2[oslo2[filter_data,
            which = TRUE]]
```
`r if (knitr::is_html_output()) '<table><div class="column-right">'`\columnbreak
With `dplyr`:
```{r, eval=F}
oslo2 %>% semi_join(filter_data,
            by = "PatientID")
```
`r if (knitr::is_html_output()) '</div></table>'`\etwocol

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc20)


#### Exercise \@ref(exr:ch5exc21) {-#ch5solutions21}
We read the HTML file and extract the table:

```{r, eval=F}
library(rvest)

wiki <- read_html("https://en.wikipedia.org/wiki/List_of_keytars")
keytars <- html_table(html_nodes(wiki, "table")[[1]], fill = TRUE)
```

We note that some non-numeric characters cause `Dates` to be a `character` vector:

```{r, eval=F}
str(keytars)
keytars$Dates
```

Noting that the first four characters in each element of the vector contain the year, we can use `substr` to only keep those characters. Finally, we use `as.numeric` to convert the text to numbers:

```{r, eval=F}
keytars$Dates <- substr(keytars$Dates, 1, 4)
keytars$Dates <- as.numeric(keytars$Dates)
keytars$Dates
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch5exc21)

## Chapter 6 {-#ch6solutions}

#### Exercise \@ref(exr:ch6exc1) {-#ch6solutions1}
The formula for converting a temperature $F$ measured in Fahrenheit to a temperature $C$ measured in Celsius is $C=(F-32)*5/9. Our function becomes:

```{r, eval=F}
FtoC <- function(F)
{
    C <- (F-32)*5/9
    return(C)
}
```

To apply it to the `Temp` column of `airquality`:

```{r, eval=F}
FtoC(airquality$Temp)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc1)

#### Exercise \@ref(exr:ch6exc2) {-#ch6solutions2}
1. We want out function to take a vector as input and return a vector containing its minimum and the maximum, without using `min` and `max`:

```{r, eval=F}
minmax <- function(x)
{
      # Sort x so that the minimum becomes the first element
      # and the maximum becomes the last element:
      sorted_x <- sort(x)
      min_x <- sorted_x[1]
      max_x <- sorted_x[length(sorted_x)]
      return(c(min_x, max_x))
}

# Check that it works:
x <- c(3, 8, 1, 4, 5)
minmax(x) # Should be 1 and 8
```

2. We want a function that computes the mean of the squared values of a vector using `mean`, and that takes additional arguments that it passes on to `mean` (e.g. `na.rm`):

```{r, eval=F}
mean2 <- function(x, ...)
{
      return(mean(x^2, ...))
}

# Check that it works:
x <- c(3, 2, 1)
mean2(x) # Should be 14/3=4.666...

# With NA:
x <- c(3, 2, NA)
mean2(x) # Should be NA
mean2(x, na.rm = TRUE) # Should be 13/2=6.5
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc2)

#### Exercise \@ref(exr:ch6exc2b) {-#ch6solutions2b}
We use `cat` to print a message about missing values, `sum(is.na(.))` to compute the number of missing values, `na.omit` to remove rows with missing data and then `summary` to print the summary:

```{r, eval=F}
na_remove <- . %T>% {cat("Missing values:", sum(is.na(.)), "\n")} %>%
                    na.omit %>% summary
  
na_remove(airquality)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc2b)

#### Exercise \@ref(exr:ch6exc2c) {-#ch6solutions2c}
The following operator allows us to plot `y` against `x`:

```{r, eval=F}
`%against%` <- function(y, x) { plot(x, y) }
```

Let's try it out:

```{r, eval=F}
airquality$Wind %against% airquality$Temp
```

Or, if we want to use `ggplot2` instead of base graphics:

```{r, eval=F}
library(ggplot2)
`%against%` <- function(y, x) { 
    df <- data.frame(x, y)
    ggplot(df, aes(x, y)) +
        geom_point()
}

airquality$Wind %against% airquality$Temp
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc2c)


#### Exercise \@ref(exr:ch6exc3) {-#ch6solutions3}
1. `FALSE`: `x` is not greater than 2.

2. `TRUE`: `|` means that at least one of the conditions need to be satisfied, and `x` is greater than `z`.

3. `FALSE`: `&` means that both conditions must be satisfied, and `x` is not greater than `y`.

4. `TRUE`: the absolute value of `x*z` is 6, which is greater than `y`.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc3)

#### Exercise \@ref(exr:ch6exc4) {-#ch6solutions4}
There are two errors: the variable name in `exists` is not between quotes and `x > 0` evaluates to a vector an not a single value. The goal is to check that all values in `x` are positive, so `all` can be used to collapse the `logical` vector `x > 0`:

```{r eval=FALSE}
x <- c(1, 2, pi, 8)

# Only compute square roots if x exists
# and contains positive values:
if(exists("x")) { if(all(x > 0)) { sqrt(x) } }
```

Alternatively, we can get a better looking solution by using `&&`:

```{r eval=FALSE}
if(exists("x") && all(x > 0)) { sqrt(x) }
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc4)

#### Exercise \@ref(exr:ch6exc5) {-#ch6solutions5}
1. To compute the mean temperature for each month in the `airquality` dataset using a loop, we loop over the 6 months:

```{r eval=FALSE}
months <- unique(airquality$Month)
meanTemp <- vector("numeric", length(months))

for(i in seq_along(months))
{
      # Extract data for month[i]:
      aq <- airquality[airquality$Month == months[i],]
      # Compute mean temperature:
      meanTemp[i] <- mean(aq$Temp)
}
```

2. Next, we use a `for` loop to compute the maximum and minimum value of each column of the `airquality` data frame, storing the results in a data frame:

```{r eval=FALSE}
results <- data.frame(min = vector("numeric", ncol(airquality)),
                      max = vector("numeric", ncol(airquality)))

for(i in seq_along(airquality))
{
      results$min[i] <- min(airquality[,i], na.rm = TRUE)
      results$max[i] <- max(airquality[,i], na.rm = TRUE)
}
results

# For presentation purposes, we can add the variable names as
# row names:
row.names(results) <- names(airquality)
```

3. Finally, we write a function to solve task 2 for any data frame:

```{r eval=FALSE}
minmax <- function(df, ...)
{
       results <- data.frame(min = vector("numeric", ncol(df)),
                             max = vector("numeric", ncol(df)))

      for(i in seq_along(df))
      {
            results$min[i] <- min(df[,i], ...)
            results$max[i] <- max(df[,i], ...)
      }
      
      # For presentation purposes, we add the variable names as
      # row names:
      row.names(results) <- names(airquality)
      
      return(results)
}

# Check that it works:
minmax(airquality)
minmax(airquality, na.rm = TRUE)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc5)

#### Exercise \@ref(exr:ch6exc5b) {-#ch6solutions5b}
1. We can create `0.25 0.5 0.75 1` in two different ways using `seq`:

```{r eval=FALSE}
seq(0.25, 1, length.out = 4)
seq(0.25, 1, by = 0.25)
```

2. We can create `1 1 1 2 2 5` using `rep`. `1` is repeated 3 times, `2` is repeated 2 times and 5 is repeated a single time:

```{r eval=FALSE}
rep(c(1, 2, 5), c(3, 2, 1))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc5b)


#### Exercise \@ref(exr:ch6exc6) {-#ch6solutions6}
We could create the same sequences using `1:ncol(airquality)` and `1:length(airquality$Temp)`, but if we accidentally apply those solutions to objects with zero length, we would run into trouble! Let's see what happens:

```{r eval=FALSE}
x <- c()
length(x)
```

Even though there are no elements in the vector, two iterations are run when we use `1:length(x)` to set the values of the control variable:

```{r eval=FALSE}
for(i in 1:length(x)) { cat("Element", i, "of the vector\n") }
```

The reason is that `1:length(x)` yields the vector `0 1`, providing two values for the control variable.

If we use `seq_along` instead, no iterations will be run, because `seq_along(x)` returns zero values:

```{r eval=FALSE}
for(i in seq_along(x)) { cat("Element", i, "of the vector\n") }
```

This is the desired behaviour - if there are no elements in the vector then the loop shouldn't run! `seq_along` is the safer option, but `1:length(x)` is arguably less opaque and therefore easier for humans to read, which also has its benefits.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc6)

#### Exercise \@ref(exr:ch6exc7) {-#ch6solutions7}
To normalise the variable, we need to map the smallest value to 0 and the largest to 1:

```{r eval=FALSE}
normalise <- function(df, ...)
{
      for(i in seq_along(df))
      {
          df[,i] <- (df[,i] - min(df[,i], ...))/(max(df[,i], ...) -
                                                   min(df[,i], ...))
      }
      return(df)
}

aqn <- normalise(airquality, na.rm = TRUE)
summary(aqn)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc7)

#### Exercise \@ref(exr:ch6exc10) {-#ch6solutions10}
We set `folder_path` to the path of the folder (making sure that the path ends with `/` (or `\\` on Windows)). We can then loop over the `.csv` files in the folder and print the names of their variables as follows:

```{r eval=FALSE}
files <- list.files(folder_path, pattern = "\\.csv$")

for(file in files)
{
      csv_data <- read.csv(paste(folder_path, file, sep = ""))
      cat(file, "\n")
      cat(names(csv_data))
      cat("\n\n")
}
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc10)

#### Exercise \@ref(exr:ch6exc8) {-#ch6solutions8}
1. The condition in the outer loop, `i < length(x)`, is used to check that the element `x[i+1]` used in the inner loop actually exists. If `i` is equal to the length of the vector (i.e. is the last element of the vector) then there is no element `x[i+1]` and consequently the run cannot go on. If this condition wasn't included, we would end up with an infinite loop.

2. The condition in the inner loop, `x[i+1] == x[i] & i < length(x)`, is used to check if the run continues. If `[i+1] == x[i]` is `TRUE` then the next element of `x` is the same as the current, meaning that the run continues. As in the previous condition, `i < length(x)` is included to make sure that we don't start looking for elements outside of `x`, which could create an infinite loop.

3. The line `run_values <- c(run_values, x[i-1])` creates a vector combining the existing elements of `run_values` with `x[i-1]`. This allows us to store the results in a vector without specifying its size in advance. Not however that this approach is slower than specifying the vector size in advance, and that you therefore should avoid it when using `for` loops.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc8)

#### Exercise \@ref(exr:ch6exc9) {-#ch6solutions9}
We modify the loop so that it skips to the next iteration if `x[i]` is `0`, and breaks if `x[i]` is `NA`:

```{r eval=FALSE}
x <- c(1, 5, 8, 0, 20, 0, 3, NA, 18, 2)

for(i in seq_along(x))
{
      if(is.na(x[i])) { break }
      if(x[i] == 0) { next }
      cat("Step", i, "- reciprocal is", 1/x[i], "\n")
}
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc9)

#### Exercise \@ref(exr:ch6exc9) {-#ch6solutions9b}
We can put a conditional statement inside each of the loops, to check that both variables are `numeric`:

```{r eval=FALSE}
cor_func <- function(df)
{
    cor_mat <- matrix(NA, nrow = ncol(df), ncol = ncol(df))
    for(i in seq_along(df))
    {
        if(!is.numeric(df[[i]])) { next }
        for(j in seq_along(df))
        {
            if(!is.numeric(df[[j]])) { next }
            cor_mat[i, j] <- cor(df[[i]], df[[j]],
                                 use = "pairwise.complete")
        }
    }
    return(cor_mat)
}

# Check that it works:
str(ggplot2::msleep)
cor_func(ggplot2::msleep)
```

An (nicer?) alternative would be to check which columns are `numeric` and loop over those:

```{r eval=FALSE}
cor_func <- function(df)
{
    cor_mat <- matrix(NA, nrow = ncol(df), ncol = ncol(df))
    indices <- which(sapply(df, class) == "numeric")
    for(i in indices)
    {
        for(j in indices)
        {
            cor_mat[i, j] <- cor(df[[i]], df[[j]],
                                 use = "pairwise.complete")
        }
    }
    return(cor_mat)
}

# Check that it works:
cor_func(ggplot2::msleep)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc9b)




#### Exercise \@ref(exr:ch6exc11) {-#ch6solutions11}
To compute the minima, we can use:

```{r eval=FALSE}
apply(airquality, 2, min, na.rm = TRUE)
```

To compute the maxima, we can use:

```{r eval=FALSE}
apply(airquality, 2, max, na.rm = TRUE)
```

We could also write a function that computes both the minimum and the maximum and returns both, and use that with `apply`:

```{r eval=FALSE}
minmax <- function(x, ...)
{
      return(c(min = min(x, ...), max = max(x, ...)))
}

apply(airquality, 2, minmax, na.rm = TRUE)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc11)

#### Exercise \@ref(exr:ch6exc12) {-#ch6solutions12}
We can for instance make use of the `minmax` function that we created in Exercise \@ref(exr:ch6exc11):

```{r eval=FALSE}
minmax <- function(x, ...)
{
      return(c(min = min(x, ...), max = max(x, ...)))
}

temps <- split(airquality$Temp, airquality$Month)

sapply(temps, minmax) # or lapply/vapply

# Or:
tapply(airquality$Temp, airquality$Month, minmax)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc12)

#### Exercise \@ref(exr:ch6exc13) {-#ch6solutions13}
To compute minima and maxima, we can use:

```{r eval=FALSE}
minmax <- function(x, ...)
{
      return(c(min = min(x, ...), max = max(x, ...)))
}
```

This time out, we want to apply this function to two variables: `Temp` and `Wind`. We can do this using `apply`:

```{r eval=FALSE}
minmax2 <- function(x, ...)
{
      return(apply(x, 2, minmax))
}
```

```{r eval=FALSE}
tw <- split(airquality[,c("Temp", "Wind")], airquality$Month)

lapply(tw, minmax2)
```

If we use `sapply` instead, we lose information about which statistic correspond to which variable, so `lapply` is a better choice here:

```{r eval=FALSE}
sapply(tw, minmax2)
```
`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc13)

#### Exercise \@ref(exr:ch6exc13b) {-#ch6solutions13b}
We can for instance make use of the `minmax` function that we created in Exercise \@ref(exr:ch6exc11):

```{r eval=FALSE}
minmax <- function(x, ...)
{
      return(c(min = min(x, ...), max = max(x, ...)))
}

library(purrr)

temps <- split(airquality$Temp, airquality$Month)
temps %>% map(minmax)
```

We can also use a single pipe chain to split the data and apply the functional:

```{r eval=FALSE}
airquality %>% split(.$Month) %>% map(~minmax(.$Temp))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc13b)

#### Exercise \@ref(exr:ch6exc13c) {-#ch6solutions13c}
Because we want to use both the variable names and their values, an `imap_*` function is appropriate here:

```{r eval=FALSE}
data_summary <- function(df)
{
    df %>% imap_dfr(~(data.frame(variable = .y,
                                 unique_values = length(unique(.x)),
                                 class = class(.x),
                                 missing_values = sum(is.na(.x)) )))
}

# Check that it works:
library(ggplot2)
data_summary(msleep)
```
`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc13c)



#### Exercise \@ref(exr:ch6exc13d) {-#ch6solutions13d}
We combine `map` and `imap` to get the desired result. `folder_path` is the path to the folder containing the `.csv` files. We must use `set_names` to set the file names as element names, otherwise only the index of each file (in the file name vector) will be printed:

```{r eval=FALSE}
list.files(folder_path, pattern = "\\.csv$") %>% 
    paste(folder_path, ., sep = "") %>% 
    set_names() %>% 
    map(read.csv) %>% 
    imap(~cat(.y, "\n", names(.x), "\n\n"))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc13d)


#### Exercise \@ref(exr:ch6exc13e) {-#ch6solutions13e}
First, we load the data and create vectors containing all combinations

```{r eval=FALSE}
library(gapminder)
combos <- gapminder %>% distinct(continent, year)
continents <- combos$continent
years <- combos$year
```

Next, we create the scatterplots:

```{r eval=FALSE}
# Create a plot for each pair:
combos_plots <- map2(continents, years, ~{
                     gapminder %>% filter(continent == .x,
                                         year == .y) %>% 
                      ggplot(aes(pop, lifeExp)) + geom_point() +
                             ggtitle(paste(.x, .y, sep =" in "))})
```

If instead we just want to save each scatterplot in a separate file, we can do so by putting `ggsave` (or `png` + `dev.off`) inside a `walk2` call:

```{r eval=FALSE}
# Create a plot for each pair:
combos_plots <- walk2(continents, years, ~{
                     gapminder %>% filter(continent == .x,
                                         year == .y) %>% 
                      ggplot(aes(pop, lifeExp)) + geom_point() +
                             ggtitle(paste(.x, .y, sep =" in "))
                      ggsave(paste(.x, .y, ".png", sep = ""),
                             width = 3, height = 3)})
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc13e)

#### Exercise \@ref(exr:ch6exc14) {-#ch6solutions14}
First, we write a function for computing the mean of a vector with a loop:

```{r eval=FALSE}
mean_loop <- function(x)
{
      m <- 0
      n <- length(x)
      for(i in seq_along(x))
      {
            m <- m + x[i]/n
      }
      return(m)
}
```

Next, we run the functions once, and then benchmark them:

```{r eval=FALSE}
x <- 1:10000
mean_loop(x)
mean(x)

library(bench)
mark(mean(x), mean_loop(x))
```

`mean_loop` is several times slower than `mean`. The memory usage of both functions is negligible.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc14)

#### Exercise \@ref(exr:ch6exc15) {-#ch6solutions15}
We can compare the three solutions as follows:

```{r eval=FALSE}
library(data.table)
library(dplyr)
library(nycflights13)
library(bench)

# Make a data.table copy of the data:
flights.dt <- as.data.table(flights)

# Wrap the solutions in functions (using global assignment to better
# monitor memory usage):
base_filter <- function() { flights0101 <<- flights[flights$month ==
                                              1 & flights$day == 1,] }
dt_filter <- function() { flights0101 <<- flights.dt[month == 1 &
                                                          day == 1,] }
dplyr_filter <- function() { flights0101 <<- flights %>% filter(
                                                month ==1, day == 1) }

# Compile the functions:
library(compiler)
base_filter <- cmpfun(base_filter)
dt_filter <- cmpfun(dt_filter)
dplyr_filter <- cmpfun(dplyr_filter)

# benchmark the solutions:
bm <- mark(base_filter(), dt_filter(), dplyr_filter())
bm
plot(bm)
```

We see that `dplyr` is substantially faster and more memory efficient than the base R solution, but that `data.table` beats them both by a margin.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch6exc15)



## Chapter 7 {-#ch7solutions}

#### Exercise \@ref(exr:ch7exc1) {-#ch7solutions1}
The parameter `replace` controls whether or not replacement is used. To draw 5 random numbers with replacement, we use:

```{r, eval=F}
sample(1:10, 5, replace = TRUE)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc1)

#### Exercise \@ref(exr:ch7exc2) {-#ch7solutions2}
As an alternative to `sample(1:10, n, replace = TRUE)` we could use `runif` to generate random numbers from `1:10`. This can be done in at least three different ways.

1. Generating (decimal) numbers between $0$ and $10$ and rounding up to the nearest integer:

```{r, eval=F}
n <- 10 # Generate 10 numbers
ceiling(runif(n, 0, 10))
```

2. Generating (decimal) numbers between $1$ and $11$ and rounding down to the nearest integer:

```{r, eval=F}
floor(runif(n, 1, 11))
```

3. Generating (decimal) numbers between $0.5$ and $10.5$ and rounding to the nearest integer:

```{r, eval=F}
round(runif(n, 0.5, 10.5))
```

Using `sample(1:10, n, replace = TRUE)` is more straightforward in this case, and is the recommended approach.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc2)

#### Exercise \@ref(exr:ch7exc3) {-#ch7solutions3}
First, we compare the histogram of the data to the normal density function:

```{r, eval=F}
library(ggplot2)
ggplot(msleep, aes(x = sleep_total)) +
      geom_histogram(colour = "black", aes(y = ..density..)) +
      geom_density(colour = "blue", size = 2) +
      geom_function(fun = dnorm, colour = "red", size = 2,
                    args = list(mean = mean(msleep$sleep_total), 
                                  sd = sd(msleep$sleep_total)))
```

The density estimate is fairly similar to the normal density, but there appear to be too many low values in the data.

Then a normal Q-Q plot:

```{r eval=FALSE}
ggplot(msleep, aes(sample = sleep_total)) +
        geom_qq() + geom_qq_line()
```

There are some small deviations from the line, but no large deviations. To decide whether these deviations are large enough to be a concern, it may be a good idea to compare this Q-Q-plot to Q-Q-plots from simulated normal data:

```{r eval=FALSE}
# Create a Q-Q-plot for the total sleep data, and store
# it in a list:
qqplots <- list(ggplot(msleep, aes(sample = sleep_total)) +
  geom_qq() + geom_qq_line() + ggtitle("Actual data"))

# Compute the sample size n: 
n <- sum(!is.na(msleep$sleep_total))

# Generate 8 new datasets of size n from a normal distribution.
# Then draw Q-Q-plots for these and store them in the list:
for(i in 2:9)
{
    generated_data <- data.frame(normal_data = rnorm(n, 10, 1))
    qqplots[[i]] <- ggplot(generated_data, aes(sample = normal_data)) +
      geom_qq() + geom_qq_line() + ggtitle("Simulated data")
}

# Plot the resulting Q-Q-plots side-by-side:
library(patchwork)
(qqplots[[1]] + qqplots[[2]] + qqplots[[3]]) /
  (qqplots[[4]] + qqplots[[5]] + qqplots[[6]]) /
  (qqplots[[7]] + qqplots[[8]] + qqplots[[9]])
```

The Q-Q-plot for the real data is pretty similar to those from the simulated samples. We can't rule out the normal distribution.

Nevertheless, perhaps the lognormal distribution would be a better fit? We can compare its density to the histogram, and draw a Q-Q plot:

```{r, eval=F}
# Histogram:
ggplot(msleep, aes(x = sleep_total)) +
      geom_histogram(colour = "black", aes(y = ..density..)) +
      geom_density(colour = "blue", size = 2) +
      geom_function(fun = dlnorm, colour = "red", size = 2,
                  args = list(meanlog = mean(log(msleep$sleep_total)), 
                              sdlog = sd(log(msleep$sleep_total))))

# Q-Q plot:
ggplot(msleep, aes(sample = sleep_total)) +
        geom_qq(distribution = qlnorm) +
        geom_qq_line(distribution = qlnorm)
```

The right tail of the distribution differs greatly from the data. If we have to choose between these two distributions, then the normal distribution seems to be the better choice.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc3)

#### Exercise \@ref(exr:ch7exc4) {-#ch7solutions4}
1. The documentation for `shapiro.test` shows that it takes a vector containing the data as input. So to apply it to the sleeping times data, we use:

```{r, eval=F}
library(ggplot2)
shapiro.test(msleep$sleep_total)
```

The p-value is $0.21$, meaning that we can't reject the null hypothesis of normality - the test does not indicate that the data is non-normal.

2. Next, we generate data from a $\chi^2(100)$ distribution, and compare its distribution to a normal density function:

```{r, eval=F}
generated_data <- data.frame(x = rchisq(2000, 100))

ggplot(generated_data, aes(x)) +
      geom_histogram(colour = "black", aes(y = ..density..)) +
      geom_density(colour = "blue", size = 2) +
      geom_function(fun = dnorm, colour = "red", size = 2,
                    args = list(mean = mean(generated_data$x), 
                                  sd = sd(generated_data$x)))
```

The fit is likely to be very good - the data is visually very close to the normal distribution. Indeed, it is rare in practice to find real data that is closer to the normal distribution than this.

However, the Shapiro-Wilk test probably tells a different story:

```{r, eval=F}
shapiro.test(generated_data$x)
```

The lesson here is that if the sample size is large enough, the Shapiro-Wilk test (and any other test for normality, for that matter) is likely to reject normality even if the deviation from normality is tiny. When the sample size is too large, the power of the test is close to 1 even for very small deviations. On the other hand, if the sample size is small, the power of the Shapiro-Wilk test is low, meaning that it can't be used to detect non-normality.

In summary, you probably shouldn't use formal tests for normality at all. And I say that as someone who has written two papers introducing new tests for normality!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc4)




#### Exercise \@ref(exr:ch7exc5) {-#ch7solutions5}
As in Section \@ref(paths), we set `file_path` to the path to `vas.csv` and load the data using the code from Exercise \@ref(exr:ch3exc4):

```{r, eval=F}
vas <- read.csv(file_path, sep = ";", dec = ",", skip = 4)
```

The null hypothesis is that the mean $\mu$ is less than or equal to 6, meaning that the alternative is that $\mu$ is greater than 6. To perform the test, we run:

```{r, eval=F}
t.test(vas$VAS, mu = 6, alternative = "greater")
```

The average VAS isn't much higher than 6 - it's 6.4 - but because the sample size is fairly large ($n=2,351$) we are still able to detect that it indeed is greater.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc5)


#### Exercise \@ref(exr:ch7exc7) {-#ch7solutions7}
First, we assume that `delta` is 0.5 and that the standard deviation is 2, and want to find the $n$ required to achieve 95 % power at a 5 % significance level:

```{r eval=FALSE}
power.t.test(power = 0.95, delta = 0.5, sd = 2, sig.level = 0.05,
             type = "one.sample", alternative = "one.sided")
```

We see than $n$ needs to be at least 175 to achieve the desired power.

The actual sample size for this dataset was $n=2,351$. Let's see what power that gives us:

```{r eval=FALSE}
power.t.test(n = 2351, delta = 0.5, sd = 2, sig.level = 0.05,
             type = "one.sample", alternative = "one.sided")
```

The power is 1 (or rather, very close to 1). We're more or less guaranteed to find statistical evidence that the mean is greater than 6 if the true mean is 6.5!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc7)

#### Exercise \@ref(exr:ch7exc8) {-#ch7solutions8}
First, let's compute the proportion of herbivores and carnivores that sleep for more than 7 hours a day:

```{r eval=FALSE}
library(ggplot2)
herbivores <- msleep[msleep$vore == "herbi",]
n1 <- sum(!is.na(herbivores$sleep_total))
x1 <- sum(herbivores$sleep_total > 7, na.rm = TRUE)

carnivores <- msleep[msleep$vore == "carni",]
n2 <- sum(!is.na(carnivores$sleep_total))
x2 <- sum(carnivores$sleep_total > 7, na.rm = TRUE)
```

The proportions are 0.625 and 0.68, respectively. To obtain a confidence interval for the difference of the two proportions, we use `binomDiffCI` as follows:

```{r eval=FALSE}
library(MKinfer)
binomDiffCI(x1, x2, n1, n2, method = "wilson")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc8)

#### Exercise \@ref(exr:ch7exc9) {-#ch7solutions9}
To run the same simulation for different $n$, we will write a function for the simulation, with the sample size `n` as an argument:

```{r eval=FALSE}
# Function for our custom estimator:
max_min_avg <- function(x)
{
      return((max(x)+min(x))/2)
}

# Function for simulation:
simulate_estimators <- function(n, mu = 0, sigma = 1, B = 1e4)
{
    cat(n, "\n")
    res <- data.frame(x_mean = vector("numeric", B),
                      x_median = vector("numeric", B),
                      x_mma = vector("numeric", B))
    
    # Start progress bar:
    pbar <- txtProgressBar(min = 0, max = B, style = 3)
    
    for(i in seq_along(res$x_mean))
    {
          x <- rnorm(n, mu, sigma)
          res$x_mean[i] <- mean(x)
          res$x_median[i] <- median(x)
          res$x_mma[i] <- max_min_avg(x)
          
          # Update progress bar
          setTxtProgressBar(pbar, i)
    }
    close(pbar)
    
    # Return a list containing the sample size,
    # and the simulation results:
    return(list(n = n,
                bias = colMeans(res-mu),
                vars = apply(res, 2, var)))
}
```

We could write a `for` loop to perform the simulation for different values of $n$. Alternatively, we can use a function, as in Section \@ref(vectorloops). Here are two examples of how this can be done:

```{r eval=FALSE}
# Create a vector of samples sizes:
n_vector <- seq(10, 100, 10)

# Run a simulation for each value in n_vector:

# Using base R:
res <- apply(data.frame(n = n_vector), 1, simulate_estimators)

# Using purrr:
library(purrr)
res <- map(n_vector, simulate_estimators)
```

Next, we want to plot the results. We need to extract the results from the list `res` and store them in a data frame, so that we can plot them using `ggplot2`.

```{r eval=FALSE}
simres <- matrix(unlist(res), 10, 7, byrow = TRUE)
simres <- data.frame(simres)
names(simres) <- names(unlist(res))[1:7]
simres
```

Transforming the data frame from wide to long format (Section \@ref(reshaping)) makes plotting easier.

We can do this using `data.table`:
```{r eval=FALSE}
library(data.table)
simres2 <- data.table(melt(simres, id.vars = c("n"),
           measure.vars = 2:7))
simres2[, c("measure", "estimator") := tstrsplit(variable,
                                        ".", fixed = TRUE)]
```

...or with `tidyr`:
```{r, eval=F}
library(tidyr)
simres %>% pivot_longer(names(simres)[2:7],
                   names_to = "variable",
                   values_to = "value") %>% 
        separate(variable,
                into = c("measure", "estimator"),
                sep = "[.]") -> simres2
```

We are now ready to plot the results:

```{r eval=FALSE}
library(ggplot2)
# Plot the bias, with a reference line at 0:
ggplot(subset(simres2, measure == "bias"), aes(n, value,
                                               col = estimator)) +
      geom_line() +
      geom_hline(yintercept = 0, linetype = "dashed") +
      ggtitle("Bias")

# Plot the variance:
ggplot(subset(simres2, measure == "vars"), aes(n, value,
                                               col = estimator)) +
      geom_line() +
      ggtitle("Variance")
```

All three estimators have a bias close to 0 for all values of $n$ (indeed, we can verify analytically that they are unbiased). The mean has the lowest variance for all $n$, with the median as a close competitor. Our custom estimator has a higher variance, that also has a slower decrease as $n$ increases. In summary, based on bias and variance, the mean is the best estimator for the mean of a normal distribution.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc9)

#### Exercise \@ref(exr:ch7exc10) {-#ch7solutions10}
To perform the same simulation with $t(3)$-distributed data, we can reuse the same code as in Exercise \@ref(exr:ch7exc9), only replacing three lines:

* The arguments of `simulate_estimators` (`mu` and `sigma` are replaced by the degrees of freedom `df` of the $t$-distribution,
* The line were the data is generated (`rt` replaces `rnorm`),
* The line were the bias is computed (the mean of the $t$-distribution is always 0).

```{r eval=FALSE}
# Function for our custom estimator:
max_min_avg <- function(x)
{
      return((max(x)+min(x))/2)
}

# Function for simulation:
simulate_estimators <- function(n, df = 3, B = 1e4)
{
    cat(n, "\n")
    res <- data.frame(x_mean = vector("double", B),
                      x_median = vector("double", B),
                      x_mma = vector("double", B))
    
    # Start progress bar:
    pbar <- txtProgressBar(min = 0, max = B, style = 3)
    
    for(i in seq_along(res$x_mean))
    {
          x <- rt(n, df)
          res$x_mean[i] <- mean(x)
          res$x_median[i] <- median(x)
          res$x_mma[i] <- max_min_avg(x)
          
          # Update progress bar
          setTxtProgressBar(pbar, i)
    }
    close(pbar)
    
    # Return a list containing the sample size,
    # and the simulation results:
    return(list(n = n,
                bias = colMeans(res-0),
                vars = apply(res, 2, var)))
}
```

To perform the simulation, we can then e.g. run the following, which has been copied from the solution to the previous exercise.

```{r eval=FALSE}
# Create a vector of samples sizes:
n_vector <- seq(10, 100, 10)

# Run a simulation for each value in n_vector:
res <- apply(data.frame(n = n_vector), 1, simulate_estimators)

# Reformat the results:
simres <- matrix(unlist(res), 10, 7, byrow = TRUE)
simres <- data.frame(simres)
names(simres) <- names(unlist(res))[1:7]
library(data.table)
simres2 <- data.table(melt(simres, id.vars = c("n"),
           measure.vars = 2:7))
simres2[, c("measure", "estimator") := tstrsplit(variable,
                                        ".", fixed = TRUE)]
# Plot the result
library(ggplot2)
# Plot the bias, with a reference line at 0:
ggplot(subset(simres2, measure == "bias"), aes(n, value,
                                               col = estimator)) +
      geom_line() +
      geom_hline(yintercept = 0, linetype = "dashed") +
      ggtitle("Bias, t(3)-distribution")

# Plot the variance:
ggplot(subset(simres2, measure == "vars"), aes(n, value,
                                               col = estimator)) +
      geom_line() +
      ggtitle("Variance, t(3)-distribution")
```

The results are qualitatively similar to those for normal data.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc10)

#### Exercise \@ref(exr:ch7exc11) {-#ch7solutions11}
We will use the functions that we created to simulate the type I error rates and powers of the three tests in Sections \@ref(simtypeI} and \@ref(simpower). Also, we must make sure to load the `MKinfer` package that contains `perm.t.test`.

To compare the type I error rates, we only need to supply the function `rt` for generating data and the parameter `df = 3` to clarify that a $t(3)$-distribution should be used:

```{r eval=FALSE}
simulate_type_I(20, 20, rt, B = 9999, df = 3)
simulate_type_I(20, 30, rt, B = 9999, df = 3)
```

Here are the results from my runs:

```{r eval=FALSE}
# Balanced sample sizes:
     p_t_test p_perm_t_test    p_wilcoxon 
   0.04340434    0.04810481    0.04860486 

# Imbalanced sample sizes:
     p_t_test p_perm_t_test    p_wilcoxon 
   0.04300430    0.04860486    0.04670467 
```

The old-school t-test appears to be a little conservative, with an actual type I error rate close to $0.043$. We can use `binomDiffCI` from `MKinfer` to get a confidence interval for the difference in type I error rate between the old-school t-test and the permutation t-test:


```{r eval=FALSE}
B <- 9999
binomDiffCI(B*0.04810481, B*0.04340434, B, B, method = "wilson")
```

The confidence interval is $(-0.001, 0.010)$. Even though the old-school t-test appeared to have a lower type I error rate, we cannot say for sure, as a difference of 0 is included in the confidence interval. Increasing the number of simulated samples to, say, $99,999$, might be required to detect any differences between the different tests.

Next, we compare the power of the tests. For the function used to simulate data for the second sample, we add a `+ 1` to shift the distribution to the right (so that the mean difference is 1):

```{r eval=FALSE}
# Balanced sample sizes:
simulate_power(20, 20, function(n) { rt(n, df = 3,) },
                       function(n) { rt(n, df = 3) + 1 },
                       B = 9999)

# Imbalanced sample sizes:
simulate_power(20, 30, function(n) { rt(n, df = 3,) },
                       function(n) { rt(n, df = 3) + 1 },
                       B = 9999)
```

Here are the results from my runs:

```{r eval=FALSE}
# Balanced sample sizes:
     p_t_test p_perm_t_test    p_wilcoxon 
    0.5127513     0.5272527     0.6524652 

# Imbalanced sample sizes:
     p_t_test p_perm_t_test    p_wilcoxon 
    0.5898590     0.6010601     0.7423742 
```

The Wilcoxon-Mann-Whitney test has the highest power in this example.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc11)

#### Exercise \@ref(exr:ch7exc12) {-#ch7solutions12}
Both the functions that we created in Section \@ref(simcorpower), `simulate_power` and `power.cor.test` include `...` in their list of arguments, which allows us to pass additional arguments to interior functions. In particular, the line in `simulate_power` where the p-value for the correlation test is computed, contains this placeholder:

```{r, eval=F}
p_values[i] <- cor.test(x[,1], x[,2], ...)$p.value
```

This means that we can pass the argument `method = "spearman"` to use the functions to compute the sample size for the Spearman correlation test. Let's try it:

```{r, eval=F}
power.cor.test(n_start = 10, rho = 0.5, power = 0.9,
               method = "spearman")
power.cor.test(n_start = 10, rho = 0.2, power = 0.8,
               method = "spearman")
```

In my runs, the Pearson correlation test required the sample sizes $n=45$ and $n=200$, whereas the Spearman correlation test required larger sample sizes: $n=50$ and $n=215$.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc12)

#### Exercise \@ref(exr:ch7excCP) {-#ch7solutionsCP}
First, we create a function that simulates the expected width of the Clopper-Pearson interval for a given $n$ and $p$:

```{r eval=FALSE}
cp_width <- function(n, p, level = 0.05, B = 999)
{
      widths <- rep(NA, B)
      
      # Start progress bar:
      pbar <- txtProgressBar(min = 0, max = B, style = 3)
      
      for(i in 1:B)
      {
            # Generate binomial data:
            x <- rbinom(1, n, p)
            
            # Compute interval width:
            interval <- binomCI(x, n, conf.level = 0.95,
                                method = "clopper-pearson")$conf.int
            widths[i] <- interval[2] - interval[1]
            
            # Update progress bar:
            setTxtProgressBar(pbar, i)
      }
      
      close(pbar)
      
      return(mean(widths))
}
```

Next, we create a function with a `while` loop that finds the sample sizes required to achieve a desired expected width:

```{r eval=FALSE}
cp_ssize <- function(n_start = 10, p, n_incr = 5, level = 0.05,
                     width = 0.1, B = 999)
{
    # Set initial values
    n <- n_start
    width_now <- 1
    
    # Check power for different sample sizes:
    while(width_now > width)
    {
        width_now <- cp_width(n, p, level, B)
        cat("n =", n, " - Width:", width_now, "\n")
        n <- n + n_incr
    }
    
    # Return the result:
    cat("\nWhen n =", n, "the expected with is", round(width, 3), "\n")
    return(n)
}
```

Finally, we run our simulation for $p=0.1$ (with expected width $0.01$) and $p=0.3$ (expected width $0.05$) and compare the results to the asymptotic answer:

```{r eval=FALSE}
# p = 0.1
# Asymptotic answer:
ssize.propCI(prop = 0.1, width = 0.01, method = "clopper-pearson")

# The asymptotic answer is 14,029 - so we need to set a fairly high
# starting value for n in our simulation!
cp_ssize(n_start = 14020, p = 0.1, n_incr = 1, level = 0.05,
         width = 0.01, B = 9999)

#######

# p = 0.3, width = 0.05
# Asymptotic answer:
ssize.propCI(prop = 0.3, width = 0.1, method = "clopper-pearson")

# The asymptotic answer is 343.
cp_ssize(n_start = 335, p = 0.3, n_incr = 1, level = 0.05,
         width = 0.1, B = 9999)
```

As you can see, the asymptotic results are very close to those obtained from the simulation, and so using `ssize.propCI` is preferable in this case, as it is much faster. 

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excCP)

#### Exercise \@ref(exr:ch7exc13) {-#ch7solutions13}
If we want to assume that the two populations have equal variances, we first have to create a centred dataset, where both groups have mean 0. We can then draw observations from this sample, and shift them by the two group means:

```{r eval=FALSE}
library(ggplot2)
boot_data <- na.omit(subset(msleep,
                  vore == "carni" | vore == "herbi")[,c("sleep_total",
                                                          "vore")])
# Compute group means and sizes:
group_means <- aggregate(sleep_total ~ vore,
                         data = boot_data, FUN = mean)
group_sizes <- aggregate(sleep_total ~ vore,
                         data = boot_data, FUN = length)
n1 <- group_sizes[1, 2]

# Create a centred dataset, where both groups have mean 0:
boot_data$sleep_total[boot_data$vore == "carni"] <- 
     boot_data$sleep_total[boot_data$vore == "carni"] -
                                      group_means[1, 2]
boot_data$sleep_total[boot_data$vore == "herbi"] <- 
     boot_data$sleep_total[boot_data$vore == "herbi"] -
                                      group_means[2, 2]

# Verify that we've centred the two groups:
aggregate(sleep_total ~ vore, data = boot_data, FUN = mean)

# First, we resample from the centred data sets. Then we label
# some observations as carnivores, and add the group mean for
# carnivores to them, and label some as herbivores and add
# that group mean instead. That way both groups are used to
# estimate the variability of the observations.
mean_diff_msleep <- function(data, i)
{ 
    # Create a sample with the same mean as the carnivore group:
    sample1 <- data[i[1:n1], 1] + group_means[1, 2]
    # Create a sample with the same mean as the herbivore group:
    sample2 <- data[i[(n1+1):length(i)], 1] + group_means[2, 2]
    # Compute the difference in means:
    return(mean(sample1$sleep_total) - mean(sample2$sleep_total))
}

library(boot)

# Do the resampling:
boot_res <- boot(boot_data,
                 mean_diff_msleep,
                 9999)

# Compute confidence intervals:
boot.ci(boot_res, type = c("perc", "bca"))
```

The resulting percentile interval is close to that which we obtained without assuming equal variances. The BCa interval is however very different.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc13)

#### Exercise \@ref(exr:ch7exc14) {-#ch7solutions14}
We use the percentile confidence interval from the previous exercise to compute p-values as follows (the null hypothesis is that the parameter is 0):

```{r eval=FALSE}
library(boot.pval)
boot.pval(boot_res, type = "perc", theta_null = 0)
```

A more verbose solution would be to write a `while` loop:

```{r eval=FALSE}
# The null hypothesis is there the difference is 0:
diff_null <- 0

# Set initial conditions:
in_interval <- TRUE
alpha <- 0

# Find the lowest alpha for which diff_null is in the
# interval:
while(in_interval)
{
    alpha <- alpha + 0.001
    interval <- boot.ci(boot_res, 
                        conf = 1 - alpha,
                        type = "perc")$percent[4:5]
    in_interval <- diff_null > interval[1] & diff_null < interval[2]
}

# Print the p-value:
alpha
```

The p-value is approximately 0.52, and we can not reject the null hypothesis.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc14)

## Chapter 8 {-#ch7bsolutions}

#### Exercise \@ref(exr:ch7exc15) {-#ch7solutions15}
We set `file_path` to the path of `sales-weather.csv`. To load the data, fit the model and plot the results, we do the following:

```{r, eval=F}
# Load the data:
weather <- read.csv(file_path, sep =";")
View(weather)

# Fit model:
m <- lm(TEMPERATURE ~ SUN_HOURS, data = weather)
summary(m)
                  
# Plot the result:
library(ggplot2)
ggplot(weather, aes(SUN_HOURS, TEMPERATURE)) +
      geom_point() + 
      geom_abline(aes(intercept = coef(m)[1], slope = coef(m)[2]),
                colour = "red")
```

The coefficient for `SUN_HOURS` is not significantly non-zero at the 5 % level. The $R^2$ value is 0.035, which is very low. There is little evidence of a connection between the number of sun hours and the temperature during this period.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc15)

#### Exercise \@ref(exr:ch7exc15b) {-#ch7solutions15b}
We fit a model using the formula:

```{r, eval=F}
m <- lm(mpg ~ ., data = mtcars)
summary(m)
```

What we've just done is to create a  model where all variables from the data frame (except `mpg`) are used as explanatory variables. This is the same model as we'd have obtained using the following (much longer) code:

```{r, eval=F}
m <- lm(mpg ~ cyl + disp + hp + drat + wt +
          qsec + vs + am + gear + carb, data = mtcars)
```

The `~ .` shorthand is very useful when you want to fit a model with a lot of explanatory variables.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc15b)

#### Exercise \@ref(exr:ch7exc16) {-#ch7solutions16}
First, we create the dummy variable:

```{r, eval=F}
weather$prec_dummy <- factor(weather$PRECIPITATION > 0)
```

Then, we fit the new model and have a look at the results. We won't centre the `SUN_HOURS` variable, as the model is easy to interpret without centring. The intercept corresponds to the expected temperature on a day with 0 `SUN_HOURS` and no precipitation.

```{r, eval=F}
m <- lm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)
summary(m)
```

Both `SUN_HOURS` and the dummy variable are significantly non-zero. In the next section, we'll have a look at how we can visualise the results of this model.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc16)

#### Exercise \@ref(exr:ch7exc17a) {-#ch7solutions17a}
We run the code to create the two data frames. We then fit a model to the first dataset `exdata1`, and make some plots:

```{r, eval=F}
m1 <- lm(y ~ x, data = exdata1)

# Show fitted values in scatterplot:
library(ggplot2)
m1_pred <- data.frame(x = exdata1$x, y_pred = predict(m1))
ggplot(exdata1, aes(x, y)) +
      geom_point() + 
      geom_line(data = m1_pred, aes(x = x, y = y_pred),
                colour = "red") 

# Residual plots:
library(ggfortify)
autoplot(m1, which = 1:6, ncol = 2, label.size = 3)
```

There are clear signs of _nonlinearity_ here, that can be seen both in the scatterplot and the residuals versus fitted plot.

Next, we do the same for the second dataset:

```{r, eval=F}
m2 <- lm(y ~ x, data = exdata2)

# Show fitted values in scatterplot:
m2_pred <- data.frame(x = exdata2$x, y_pred = predict(m2))
ggplot(exdata2, aes(x, y)) +
      geom_point() + 
      geom_line(data = m2_pred, aes(x = x, y = y_pred),
                colour = "red") 

# Residual plots:
library(ggfortify)
autoplot(m2, which = 1:6, ncol = 2, label.size = 3)
```

There is a strong indication of _heteroscedasticity_. As is seen e.g. in the scatterplot and in the scale-location plot, the residuals appear to vary more the larger `x` becomes.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc17a)


#### Exercise \@ref(exr:ch7exc17) {-#ch7solutions17}
1. First, we plot the observed values against the fitted values for the two models.

```{r eval=FALSE}
# The two models:
m1 <- lm(TEMPERATURE ~ SUN_HOURS, data = weather)
m2 <- lm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)

n <- nrow(weather)
models <- data.frame(Observed = rep(weather$TEMPERATURE, 2),
                     Fitted = c(predict(m1), predict(m2)),
                     Model = rep(c("Model 1", "Model 2"), c(n, n)))

ggplot(models, aes(Fitted, Observed)) +
      geom_point(colour = "blue") +
      facet_wrap(~ Model, nrow = 3) +
      geom_abline(intercept = 0, slope = 1) +
      xlab("Fitted values") + ylab("Observed values")
```

The first model only predicts values within a fairly narrow interval. The second model does a somewhat better job of predicting high temperatures.

2. Next, we create residual plots for the second model.

```{r, eval=F}
library(ggfortify)
autoplot(m2, which = 1:6, ncol = 2, label.size = 3)
```

There are no clear trends or signs of heteroscedasticity. There are some deviations from normality in the tail of the residual distribution. There are a few observations - 57, 76 and 83, that have fairly high Cook's distance. Observation 76 also has a very high leverage. Let's have a closer look at them:

```{r, eval=F}
weather[c(57, 76, 83),]
```

As we can see using `sort(weather$SUN_HOURS)` and `min(weather$TEMPERATURE)`, observation 57 corresponds to the coldest day during the period, and observations 76 and 83 to the two days with the highest numbers of sun hours. Neither of them deviate too much from other observations though, so it shouldn't be a problem that their Cook's distances are little high.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc17)

#### Exercise \@ref(exr:ch7exc18) {-#ch7solutions18}
We run `boxcox` to find a suitable Box-Cox transformation for our model:

```{r eval=FALSE}
m <- lm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)

library(MASS)
boxcox(m)
```

You'll notice an error message, saying:

```{r eval=FALSE}
Error in boxcox.default(m) : response variable must be positive
```

The `boxcox` method can only be used for non-negative response variables. We can solve this e.g. by transforming the temperature (which currently is in degrees Celsius) to degrees Fahrenheit, or by adding a constant to the temperature (which only will affect the intercept of the model, and not the slope coefficients). Let's try the former:

```{r eval=FALSE}
weather$TEMPERATUREplus10 <- weather$TEMPERATURE + 10
m <- lm(TEMPERATUREplus10 ~ SUN_HOURS*prec_dummy, data = weather)

boxcox(m)
```

The value $\lambda = 1$ is inside the interval indicated by the dotted lines. This corresponds to no transformation at all, meaning that there is no indication that we should transform our response variable.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc18)

#### Exercise \@ref(exr:ch7exc19) {-#ch7solutions19}
We refit the model using:

```{r, eval=F}
library(lmPerm)
m <- lmp(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)
summary(m)
```

The main effects are still significant at the 5 % level.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc19)

#### Exercise \@ref(exr:ch7exc20) {-#ch7solutions20}
The easiest way to do this is to use `boot_summary`:

```{r eval=FALSE}
library(MASS)
m <- rlm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)

library(boot.pval)
boot_summary(m, type = "perc", method = "residual")
```

We can also use `Boot`:

```{r eval=FALSE}
library(car)
boot_res <- Boot(m, method = "residual")

# Compute 95 % confidence intervals using confint
confint(boot_res, type = "perc")
```

If instead we want to use `boot`, we begin by fitting the model:

```{r eval=FALSE}
library(MASS)
m <- rlm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)
```

Next, we compute the confidence intervals using `boot` and `boot.ci` (note that we use `rlm` inside the `coefficients` function!):

```{r eval=FALSE}
library(boot)

coefficients <- function(formula, data, i, predictions, residuals) {
      # Create the bootstrap value of response variable by
      # adding a randomly drawn residual to the value of the
      # fitted function for each observation:
      data[,all.vars(formula)[1]] <- predictions + residuals[i]
      
      # Fit a new model with the bootstrap value of the response
      # variable and the original explanatory variables:
      m <- rlm(formula, data = data)
      return(coef(m))
}

# Fit the linear model:
m <- rlm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)

# Compute scaled and centred residuals:
res <- residuals(m)/sqrt(1 - lm.influence(m)$hat)
res <- res - mean(res)

# Run the bootstrap, extracting the model formula and the
# fitted function from the model m:
boot_res <- boot(data = mtcars, statistic = coefficients,
                R = 999, formula = formula(m),
                predictions = predict(m),
                residuals = res)

# Compute confidence intervals:
boot.ci(boot_res, type = "perc", index = 1) # Intercept
boot.ci(boot_res, type = "perc", index = 2) # Sun hours
boot.ci(boot_res, type = "perc", index = 3) # Precipitation dummy
boot.ci(boot_res, type = "perc", index = 4) # Interaction term
```

Using the connection between hypothesis tests and confidence intervals, to see whether an effect is significant at the 5 % level, you can check whether 0 is contained in the confidence interval. If not, then the effect is significant.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc20)

#### Exercise \@ref(exr:ch7exc20b) {-#ch7solutions20b}
We fit the model and then use `boot_summary` with `method = "case"`:

```{r eval=FALSE}
m <- lm(mpg ~ hp + wt, data = mtcars)

library(boot.pval)
boot_summary(m, type = "perc", method = "case", R = 9999)
boot_summary(m, type = "perc", method = "residual", R = 9999)
```

In this case, the resulting confidence intervals are similar to what we obtained with residual resampling.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc20b)

#### Exercise \@ref(exr:ch7exc21) {-#ch7solutions21}
First, we prepare the model and the data:

```{r, eval=F}
m <- lm(TEMPERATURE ~ SUN_HOURS*prec_dummy, data = weather)
new_data <- data.frame(SUN_HOURS = 0, prec_dummy = "TRUE")
```

We can then compute the prediction interval using `boot.ci`:

```{r eval=FALSE}
boot_pred <- function(data, new_data, model, i,
                      formula, predictions, residuals){
      data[,all.vars(formula)[1]] <- predictions + residuals[i]
      m_boot <- lm(formula, data = data)
      predict(m_boot, newdata = new_data) + 
         sample(residuals(m_boot), nrow(new_data))
}

library(boot)

boot_res <- boot(data = m$model,
                     statistic = boot_pred,
                     R = 999,
                     model = m,
                     new_data = new_data,
                     formula = formula(m),
                     predictions = predict(m),
                     residuals = residuals(m))

# 95 % bootstrap prediction interval:
boot.ci(boot_res, type = "perc")
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc21)

#### Exercise \@ref(exr:ch7exc21a) {-#ch7solutions21a}
`autoplot` uses standard `ggplot2` syntax, so by adding `colour = mtcars$cyl` to `autoplot`, we can plot different groups in different colours:

```{r eval=FALSE}
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am)

# Fit model and print ANOVA table:
m <- aov(mpg ~ cyl + am, data = mtcars)

library(ggfortify)
autoplot(m, which = 1:6, ncol = 2, label.size = 3,
         colour = mtcars$cyl)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc21a)


#### Exercise \@ref(exr:ch7exc21b) {-#ch7solutions21b}
We rerun the analysis:

```{r eval=FALSE}
# Convert variables to factors:
mtcars$cyl <- factor(mtcars$cyl)
mtcars$am <- factor(mtcars$am)

# Fit model and print ANOVA table:
library(lmPerm)
m <- aovp(mpg ~ cyl + am, data = mtcars)
summary(m)
```

Unfortunately, if you run this multiple times, the p-values will vary a lot. To fix that, you need to increase the maximum number of iterations allowed, by increasing `maxIter`, and changing the condition for the accuracy of the p-value by lowering `Ca`:

```{r eval=FALSE}
m <- aovp(mpg ~ cyl + am, data = mtcars,
          perm = "Prob",
          Ca = 1e-3,
          maxIter = 1e6)
summary(m)
```

According to `?aovp`, the `seqs` arguments controls which type of table is produced. It's perhaps not perfectly clear from the documentation, but the default `seqs = FALSE` corresponds to a type III table, whereas `seqs = TRUE` corresponds to a type I table:

```{r eval=FALSE}
# Type I table:
m <- aovp(mpg ~ cyl + am, data = mtcars,
          seqs = TRUE,
          perm = "Prob",
          Ca = 1e-3,
          maxIter = 1e6)
summary(m)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc21b)


#### Exercise \@ref(exr:ch7exc21c) {-#ch7solutions21c}
We can run the test using the usual formula notation:

```{r eval=FALSE}
kruskal.test(mpg ~ cyl, data = mtcars)
```

The p-value is very low, and we conclude that the fuel consumption differs between the three groups.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7exc21c)


#### Exercise \@ref(exr:ch7excGLM1) {-#ch7solutionsGLM1}
We set `file_path` to the path of `shark.csv` and then load and inspect the data:

```{r, eval=F}
sharks <- read.csv(file_path, sep =";")
View(sharks)
```

We need to convert the `Age` variable to a `numeric`, which will cause us to lose information ("NAs introduced by coercion") about the age of the persons involved in some attacks, i.e. those with values like `20's` and `25 or 28`, which cannot be automatically coerced into numbers:

```{r, eval=F}
sharks$Age <- as.numeric(sharks$Age)
```

Similarly, we'll convert `Sex.` and `Fatal..Y.N.` to `factor` variables:

```{r, eval=F}
sharks$Sex. <- factor(sharks$Sex, levels = c("F", "M"))
sharks$Fatal..Y.N. <- factor(sharks$Fatal..Y.N., levels = c("N", "Y"))
```

We can now fit the model:

```{r eval=FALSE}
m <- glm(Fatal..Y.N. ~ Age + Sex., data = sharks, family = binomial)
summary(m)
```

Judging from the p-values, there is no evidence that sex and age affect the probability of an attack being fatal.


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM1)

#### Exercise \@ref(exr:ch7excGLM1b) {-#ch7solutionsGLM1b}
We use the same logistic regression model for the `wine` data as before:

```{r, eval=F}
m <- glm(type ~ pH + alcohol, data = wine, family = binomial)
```

The `broom` functions work also for generalised linear models. As for linear models, `tidy` gives the table of coefficients and p-values, `glance` gives some summary statistics, and `augment` adds fitted values and residuals to the original dataset:

```{r, eval=F}
library(broom)
tidy(m)
glance(m)
augment(m)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM1b)

#### Exercise \@ref(exr:ch7excGLM2) {-#ch7solutionsGLM2}
Using the model `m` from the other exercise, we can now do the following.

1. Compute asymptotic confidence intervals:

```{r, eval=F}
library(MASS)
confint(m)
```

2. Next, we compute bootstrap confidence intervals and p-values. In this case, the response variable is missing for a lot of observations. In order to use the same number of observations in our bootstrapping as when fitting the original model, we need to add a line to remove those observation (as in Section \@ref(conditions2)).

```{r eval=FALSE}
library(boot.pval)
# Try fitting the model without removing missing values:
boot_summary(m, type = "perc", method = "case")

# Remove missing values, refit the model, and then run
# boot_summary again:
sharks2 <- na.omit(sharks, "Fatal..Y.N.")
m <- glm(Fatal..Y.N. ~ Age + Sex., data = sharks2,
         family = binomial)
boot_summary(m, type = "perc", method = "case")
```

If you prefer writing your own bootstrap code, you could proceed as follows:

```{r eval=FALSE}
library(boot)

coefficients <- function(formula, data, predictions, ...) {
  # Remove rows where the response variable is missing:
  data <- na.omit(data, all.vars(formula)[1])
  
  # Check whether the response variable is a factor or
  # numeric, and then resample:
  if(is.factor(data[,all.vars(formula)[1]])) {
      # If the response variable is a factor:
      data[,all.vars(formula)[1]] <- 
      factor(levels(data[,all.vars(formula)[1]])[1 + rbinom(nrow(data),
                                          1, predictions)]) } else {
      # If the response variable is numeric:
      data[,all.vars(formula)[1]] <- 
         unique(data[,all.vars(formula)[1]])[1 + rbinom(nrow(data),
                                              1, predictions)] }
  
      m <- glm(formula, data = data, family = binomial)
      return(coef(m))
}

boot_res <- boot(data = sharks, statistic = coefficients,
                R=999, formula = formula(m),
                predictions = predict(m, type = "response"))

# Compute confidence intervals:
boot.ci(boot_res, type = "perc", index = 1) # Intercept
boot.ci(boot_res, type = "perc", index = 2) # Age
boot.ci(boot_res, type = "perc", index = 3) # Sex.M

# Compute p-values:

# The null hypothesis is that the effect (beta coefficient)
# is 0:
beta_null <- 0

# Set initial conditions:
in_interval <- TRUE
alpha <- 0

# Find the lowest alpha for which beta_null is in the
# interval:
while(in_interval)
{
    # Based on the asymptotic test, we expect the p-value
    # to not be close to 0. We therefore increase alpha by
    # 0.01 instead of 0.001 in each iteration.
    alpha <- alpha + 0.01
    interval <- boot.ci(boot_res, 
                        conf = 1 - alpha,
                        type = "perc", index = 2)$perc[4:5]
    in_interval <- beta_null > interval[1] & beta_null < interval[2]
}

# Print the p-value:
alpha
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM2)

#### Exercise \@ref(exr:ch7excGLM3) {-#ch7solutionsGLM3}
We draw a binned residual plot for our model:

```{r eval=FALSE}
m <- glm(Fatal..Y.N. ~ Age + Sex., data = sharks, family = binomial)

library(arm)
binnedplot(predict(m, type = "response"),
           residuals(m, type = "response"))
```

There are a few points outside the interval, but not too many. There is not trend, i.e. there is for instance no sign that the model has a worse performance when it predicts a larger probability of a fatal attack.

Next, we plot the Cook's distances of the observations:

```{r eval=FALSE}
res <- data.frame(Index = 1:length(cooks.distance(m)),
                  CooksDistance = cooks.distance(m))

# Plot index against the Cook's distance to find
# influential points:
ggplot(res, aes(Index, CooksDistance)) +
      geom_point() +
      geom_text(aes(label = ifelse(CooksDistance > 0.05,
                                   rownames(res), "")),
                hjust = 1.1)
```

There are a few points with a high Cook's distance. Let's investigate point 116, which has the highest distance:

```{r eval=FALSE}
sharks[116,]
```

This observation corresponds to the oldest person in the dataset, and a fatal attack. Being an extreme observation, we'd expect it to have a high Cook's distance.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM3)

#### Exercise \@ref(exr:ch7excGLM4) {-#ch7solutionsGLM4}
First, we have a look at the `quakes` data:

```{r, eval=F}
?quakes
View(quakes)
```

We then fit a Poisson regression model with `stations` as response variable and `mag` as explanatory variable:

```{r eval=FALSE}
m <- glm(stations ~ mag, data = quakes, family = poisson)
summary(m)
```

We plot the fitted values against the observed values, create a binned residual plot, and perform a test of overdispersion:

```{r eval=FALSE}
# Plot observed against fitted:
res <- data.frame(Observed = quakes$stations,
                  Fitted = predict(m, type = "response"))

ggplot(res, aes(Fitted, Observed)) +
      geom_point(colour = "blue") +
      geom_abline(intercept = 0, slope = 1) +
      xlab("Fitted values") + ylab("Observed values")

# Binned residual plot:
library(arm)
binnedplot(predict(m, type = "response"),
           residuals(m, type = "response"))

# Test overdispersion
library(AER)
dispersiontest(m, trafo = 1)
```

Visually, the fit is pretty good. As indicated by the test, there are however signs of overdispersion. Let's try a negative binomial regression instead.

```{r eval=FALSE}
# Fit NB regression:
library(MASS)
m2 <- glm.nb(stations ~ mag, data = quakes)
summary(m2)

# Compare fit of observed against fitted:
n <- nrow(quakes)
models <- data.frame(Observed = rep(quakes$stations, 2),
                     Fitted = c(predict(m, type = "response"),
                                predict(m2, type = "response")),
                     Model = rep(c("Poisson", "NegBin"),
                                 c(n, n)))

ggplot(models, aes(Fitted, Observed)) +
      geom_point(colour = "blue") +
      facet_wrap(~ Model, nrow = 3) +
      geom_abline(intercept = 0, slope = 1) +
      xlab("Fitted values") + ylab("Observed values")
```

The difference between the models is tiny. We'd probably need to include more variables to get a real improvement of the model.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM4)

#### Exercise \@ref(exr:ch7excGLM5) {-#ch7solutionsGLM5}
We can get confidence intervals for the $\beta_j$ using `boot_summary`, as in previous sections. To get bootstrap confidence intervals for the rate ratios $e^{\beta_j}$, we exponentiate the confidence intervals for the $\beta_j$:

```{r eval=FALSE}
library(boot.pval)
boot_table <- boot_summary(m, type = "perc", method = "case")
boot_table

# Confidence intervals for rate ratios:
exp(boot_table[, 2:3])
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excGLM5)

#### Exercise \@ref(exr:ch7excLMM1) {-#ch7solutionsLMM1}
First, we load the data and have a quick look at it:

```{r, eval=F}
library(nlme)
?Oxboys
View(Oxboys)
```

Next, we make a plot for each boy (each subject):

```{r eval=FALSE}
ggplot(Oxboys, aes(age, height, colour = Subject)) +
      geom_point() +
      theme(legend.position = "none") +
      facet_wrap(~ Subject, nrow = 3) +
      geom_smooth(method = "lm", colour = "black", se = FALSE)
```

Both intercepts and slopes seem to vary between individuals. Are they correlated?

```{r eval=FALSE}
# Collect the coefficients from each linear model:
library(purrr)
Oxboys %>% split(.$Subject) %>% 
              map(~ lm(height ~ age, data = .)) %>% 
              map(coef) -> coefficients

# Convert to a data frame:
coefficients <- data.frame(matrix(unlist(coefficients),
                  nrow = length(coefficients),
                  byrow = TRUE),
                  row.names = names(coefficients))
names(coefficients) <- c("Intercept", "Age")

# Plot the coefficients:
ggplot(coefficients, aes(Intercept, Age,
                         colour = row.names(coefficients))) +
      geom_point() +
      geom_smooth(method = "lm", colour = "black", se = FALSE) +
      labs(fill = "Subject")

# Test the correlation:
cor.test(coefficients$Intercept, coefficients$Age)
```

There is a strong indication that the intercepts and slopes have a positive correlation. We'll therefore fit a linear mixed model with correlated random intercepts and slopes:

```{r eval=FALSE}
m <- lmer(height ~ age + (1 + age|Subject), data = Oxboys)
summary(m, correlation = FALSE)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM1)

#### Exercise \@ref(exr:ch7excLMM1) {-#ch7solutionsLMM1b}
We'll use the model that we fitted to the `Oxboys` data in the previous exercise:

```{r, eval=F}
library(lme4)
library(nlme)
m <- lmer(height ~ age + (1 + age|Subject), data = Oxboys)
```

First, we install `broom.mixed`:

```{r, eval=F}
install.packages("broom.mixed")
```

Next, we obtain the summary table as a data frame using `tidy`:

```{r, eval=F}
library(broom.mixed)
tidy(m)
```

As you can see, fixed and random effects are shown in the same table. However, different information is displayed for the two types of variables (just as when we use `summary`).

Note that if we fit the model after loading the `lmerTest`, the `tidy` table also includes p-values:

```{r, eval=F}
library(lmerTest)
m <- lmer(height ~ age + (1 + age|Subject), data = Oxboys)
tidy(m)
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM1b)

#### Exercise \@ref(exr:ch7excLMM2) {-#ch7solutionsLMM2}
We use the same model as in the previous exercise:

```{r eval=FALSE}
library(nlme)
m <- lmer(height ~ age + (1 + age|Subject), data = Oxboys)
```

We make some diagnostic plots:

```{r eval=FALSE}
library(ggplot2)
fm <- fortify.merMod(m)

# Plot residuals:
ggplot(fm, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  xlab("Fitted values") + ylab("Residuals")

# Compare the residuals of different subjects:
ggplot(fm, aes(Subject, .resid)) +
  geom_boxplot() +
  coord_flip() +
  ylab("Residuals")

# Observed values versus fitted values:
ggplot(fm, aes(.fitted, height)) +
  geom_point(colour = "blue") +
  facet_wrap(~ Subject, nrow = 3) +
  geom_abline(intercept = 0, slope = 1) +
  xlab("Fitted values") + ylab("Observed values")

## Q-Q plot of residuals:
ggplot(fm, aes(sample = .resid)) +
  geom_qq() + geom_qq_line()

## Q-Q plot of random effects:
ggplot(ranef(m)$Subject, aes(sample = `(Intercept)`)) +
  geom_qq() + geom_qq_line()
ggplot(ranef(m)$Subject, aes(sample = `age`)) +
  geom_qq() + geom_qq_line()
```

Overall, the fit seems very good. There may be some heteroscedasticity, but nothing too bad. Some subjects have a larger spread in their residuals, which is to be expected in this case - growth in children is non-constant, and a large negative residual is therefore likely to be followed by a large positive residual, and vice versa. The regression errors and random effects all appear to be normally distributed.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM2)

#### Exercise \@ref(exr:ch7excLMM2b) {-#ch7solutionsLMM2b}
To look for an interaction between `TVset` and `Assessor`, we draw an interaction plot:

```{r eval=FALSE}
library(lmerTest)
interaction.plot(TVbo$Assessor, TVbo$TVset,
                 response = TVbo$Coloursaturation)
```

The lines overlap and follow different patterns, so there appears to be an interaction. There are two ways in which we could include this. Which we choose depends on what we think our _clusters of correlated measurements_ are. If only the assessors are clusters, we'd include this as a random slope:

```{r eval=FALSE}
m <- lmer(Coloursaturation ~ TVset*Picture + (1 + TVset|Assessor),
         data = TVbo)
m
anova(m)
```

In this case, we think that there is a fixed interaction between each pair of assessor and TV set.

However, if we think that the interaction is random and varies between repetitions, the situation is different. In this case the combination of assessor and TV set are clusters of correlated measurements (which could make sense here, because we have repeated measurements for each assessor-TV set pair). We can then include the interaction as a nested random effect:

```{r eval=FALSE}
m <- lmer(Coloursaturation ~ TVset*Picture + (1|Assessor/TVset),
         data = TVbo)
m
anova(m)
```

Neither of these approaches is inherently superior to the other. Which we choose is a matter of what we think best describes the correlation structure of the data. 

In either case, the results are similar, and all fixed effects are significant at the 5 % level.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM2b)

#### Exercise \@ref(exr:ch7excLMM3) {-#ch7solutionsLMM3}
`BROOD`, `INDEX` (subject ID number) and `LOCATION` all seem like they could cause measurements to be correlated, and so are good choices for random effects. To keep the model simple, we'll only include random intercepts. We fit a mixed Poisson regression using `glmer`:

```{r eval=FALSE}
library(lme4)
m <- glmer(TICKS ~ YEAR + HEIGHT + (1|BROOD) + (1|INDEX) + (1|LOCATION),
           data = grouseticks, family = poisson)
summary(m, correlation = FALSE)
```

To compute the bootstrap confidence interval for the effect of `HEIGHT`, we use `boot_summary`:

```{r eval=FALSE}
library(boot.pval)
boot_summary(m, type = "perc", R = 100)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM3)

#### Exercise \@ref(exr:ch7excLMM3b) {-#ch7solutionsLMM3b}
The `ovarian` data comes from a randomised trial comparing two treatments for ovarian cancer:

```{r eval=FALSE}
library(survival)
?ovarian
str(ovarian)
```

Let's plot Kaplan-Meier curves to compare the two treatments:

```{r eval=FALSE}
library(ggfortify)
m <- survfit(Surv(futime, fustat) ~ rx, data = ovarian)
autoplot(m)
```

The parametric confidence interval overlap a lot. Let's compute a bootstrap confidence interval for the difference in the 75 % quantile of the survival times. We set the quantile level using the `q` argument in `bootkm`:

```{r eval=FALSE}
library(Hmisc)

# Create a survival object:
survobj <- Surv(ovarian$futime, ovarian$fustat)

# Get bootstrap replicates of the 75 % quantile for the
# survival time for the two groups:
q75_surv_time_1 <- bootkm(survobj[ovarian$rx == 1],
                                  q = 0.75, B = 999)
q75_surv_time_2 <- bootkm(survobj[ovarian$rx == 2],
                                q = 0.75, B = 999)

# 95 % bootstrap confidence interval for the difference in
# 75 % quantile of the survival time distribution:
quantile(q75_surv_time_2 - q75_surv_time_1,
         c(.025,.975), na.rm=TRUE)
```

The resulting confidence interval is very wide!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM3b)

#### Exercise \@ref(exr:ch7excLMM3c) {-#ch7solutionsLMM3c}
1. First, we fit a Cox regression model. From `?ovarian` we see that the survival/censoring times are given by `futime` and the censoring status by `fustat`.

```{r eval=FALSE}
library(survival)
m <- coxph(Surv(futime, fustat) ~ age + rx, data = ovarian)
summary(m)
```

According to the p-value in the table, which is 0.2, there is no significant difference between the two treatment groups. Put differently, there is no evidence that the hazard ratio for treatment isn't equal to 1.

To assess the assumption of proportional hazards, we plot the Schoenfeld residuals:

```{r eval=FALSE}
library(survminer)
ggcoxzph(cox.zph(m), var = 1)
ggcoxzph(cox.zph(m), var = 2)
```

There is no clear trend over time, and the assumption appears to hold.

2. To compute a bootstrap confidence interval for the hazard ratio for age, we follow the same steps as in the `lung` example, replacing the variables from that model with the variables in our new model.

```{r eval=FALSE}
boot_fun <- function(data, formula) {
     m_boot <- coxph(formula, data = data)
     return(exp(coef(m_boot)))
}

# Run the resampling:
library(boot)
# We use strata = ovarian$rx to get the same number of patients from
# each treatment group in each sample:
boot_res <- censboot(ovarian[,c("futime", "fustat", "age", "rx")],
                     boot_fun, R = 999, strata = ovarian$rx,
                     formula = formula(Surv(futime, fustat) ~ age + rx))

# Compute the percentile bootstrap confidence interval:
boot.ci(boot_res, type = "perc", index = 1) # CI for age
```

All values in the confidence interval are positive, meaning that we are fairly sure that the hazard increases with age.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM3c)



#### Exercise \@ref(exr:ch7excLMM4) {-#ch7solutionsLMM4}
First, we fit the model:

```{r eval=FALSE}
m <- coxph(Surv(futime, status) ~ age + type + trt,
           cluster = id, data = retinopathy)
summary(m)
```

To check the assumption of proportional hazards, we make a residual plot:

```{r eval=FALSE}
library(survminer)
ggcoxzph(cox.zph(m), var = 1)
ggcoxzph(cox.zph(m), var = 2)
ggcoxzph(cox.zph(m), var = 3)
```

As there are no trends over time, there is no evidence against the assumption of proportional hazards.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM4)


#### Exercise \@ref(exr:ch7excLMM5) {-#ch7solutionsLMM5}
We fit the model using `survreg`:

```{r eval=FALSE}
library(survival)
m <- survreg(Surv(futime, fustat) ~ ., data = ovarian,
                dist = "loglogistic")
```

To get the estimated effect on survival times, we exponentiate the coefficients:

```{r eval=FALSE}
exp(coef(m))
```

According to the model, the survival time increases 1.8 times for patients in treatment group 2, compared to patients in treatment group 1. Running `summary(m)` shows that the p-value for `rx` is 0.05, meaning that the result isn't significant at the the 5 % level (albeit with the smallest possible margin!).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLMM5)

#### Exercise \@ref(exr:ch7excLoD1) {-#ch7solutionsLoD1}
We set `file_path` to the path to `il2rb.csv` and then load the data (note that it uses a decimal comma!):

```{r eval=FALSE}
biomarkers <- read.csv(file_path, sep = ";", dec = ",")
```

Next, we check which measurements that are nondetects, and impute the detection limit 0.25:

```{r eval=FALSE}
censored <- is.na(biomarkers$IL2RB)
biomarkers$IL2RB[censored] <- 0.25

# Check the proportion of nondetects:
mean(censored)
```

27.5 % of the observations are left-censored.

To compute bootstrap confidence intervals for the mean of the biomarker level distribution under the assumption of lognormality, we can now use `elnormAltCensored`:

```{r eval=FALSE}
elnormAltCensored(biomarkers$IL2RB, censored, method = "mle",
              ci = TRUE,  ci.method = "bootstrap",
              n.bootstraps = 999)$interval$limits
```


`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLoD1)

#### Exercise \@ref(exr:ch7excLoD2) {-#ch7solutionsLoD2}
We set `file_path` to the path to `il2rb.csv` and then load and prepare the data:

```{r eval=FALSE}
biomarkers <- read.csv(file_path, sep = ";", dec = ",")
censored <- is.na(biomarkers$IL2RB)
biomarkers$IL2RB[censored] <- 0.25
```

Based on the recommendations in Zhang et al. (2009), we can now run a Wilcoxon-Mann-Whitney test. Because we've imputed the LoD for the nondetects, all observations are included in the test:

```{r eval=FALSE}
wilcox.test(IL2RB ~ Group, data = biomarkers)
```

The p-value is 0.42, and we do not reject the null hypothesis that there is no difference in location.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch7excLoD2)

## Chapter 9 {-#ch8solutions}

#### Exercise \@ref(exr:ch8exc1) {-#ch8solutions1}
1. We load the data and compute the expected values using the formula $y = 2x_1-x_2+x_3\cdot x_2$:

```{r eval=FALSE}
exdata <- data.frame(x1 = c(0.87, -1.03, 0.02, -0.25, -1.09, 0.74,
          0.09, -1.64, -0.32, -0.33, 1.40, 0.29, -0.71, 1.36, 0.64,
          -0.78, -0.58, 0.67, -0.90, -1.52, -0.11, -0.65, 0.04,
          -0.72, 1.71, -1.58, -1.76, 2.10, 0.81, -0.30),
          x2 = c(1.38, 0.14, 1.46, 0.27, -1.02, -1.94, 0.12, -0.64,
          0.64, -0.39, 0.28, 0.50, -1.29, 0.52, 0.28, 0.23, 0.05,
          3.10, 0.84, -0.66, -1.35, -0.06, -0.66, 0.40, -0.23,
          -0.97, -0.78, 0.38, 0.49, 0.21),
          x3 = c(1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,
          1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1),
          y = c(3.47, -0.80, 4.57, 0.16, -1.77, -6.84, 1.28, -0.52,
          1.00, -2.50, -1.99, 1.13, -4.26, 1.16, -0.69, 0.89, -1.01,
          7.56, 2.33, 0.36, -1.11, -0.53, -1.44, -0.43, 0.69, -2.30,
          -3.55, 0.99, -0.50, -1.67))

exdata$Ey = 2*exdata$x2 - exdata$x3 + exdata$x3*exdata$x2
```

Next, we plot the expected values against the actual values:

```{r eval=FALSE}
library(ggplot2)
ggplot(exdata, aes(Ey, y)) + geom_point()
```

The points seem to follow a straight line, and a linear model seems appropriate.

2. Next, we fit a linear model to the first 20 observations:

```{r eval=FALSE}
m <- lm(y ~ x1 + x2 + x3, data = exdata[1:20,])
summary(m)
```

The $R^2$-value is pretty high: 0.91. `x1` and `x2` both have low p-values, as does the F-test for the regression. We can check the model fit by comparing the fitted values to the actual values. We add a red line that the points should follow if we have a good fit:

```{r eval=FALSE}
ggplot(exdata[1:20,], aes(y, predict(m))) + 
   geom_point() +
   geom_abline(intercept = 0, slope = 1, col = "red")
```

The model seems to be pretty good! Now let's see how well it does when faced with new data.

3. We make predictions for all 10 observations:

```{r eval=FALSE}
exdata$predictions <- predict(m, exdata)
```

We can plot the results for the last 10 observations, which weren't used when we fitted the model:

```{r eval=FALSE}
ggplot(exdata[21:30,], aes(y, predictions)) + 
   geom_point() +
   geom_abline(intercept = 0, slope = 1, col = "red")
```

The results are much worse than before! The correlation between the predicted values and the actual values is very low:

```{r eval=FALSE}
cor(exdata[21:30,]$y, exdata[21:30,]$predictions)
```

Despite the good in-sample performance (as indicated e.g. by the high $R^2$), the model doesn't seem to be very useful for prediction.

4. Perhaps you noted that the effect of `x3` wasn't significant in the model. Perhaps the performance will improve if we remove it? Let's try!

```{r eval=FALSE}
m <- lm(y ~ x1 + x2, data = exdata[1:20,])
summary(m)
```

The p-values and $R^2$ still look very promising. Let's make predictions for the new observations and check the results:

```{r eval=FALSE}
exdata$predictions <- predict(m, exdata)

ggplot(exdata[21:30,], aes(y, predictions)) + 
   geom_point() +
   geom_abline(intercept = 0, slope = 1, col = "red")

cor(exdata[21:30,]$y, exdata[21:30,]$predictions)
```

The predictions are no better than before - indeed, the correlation between the actual and predicted values is even lower this time out!

5. Finally, we fit a correctly specified model and evaluate the results:

```{r eval=FALSE}
m <- lm(y ~ x1 + x2 + x3*x2, data = exdata[1:20,])
summary(m)

exdata$predictions <- predict(m, exdata)

ggplot(exdata[21:30,], aes(y, predictions)) + 
   geom_point() +
   geom_abline(intercept = 0, slope = 1, col = "red")

cor(exdata[21:30,]$y, exdata[21:30,]$predictions)
```

The predictive performance of the model remains low, which shows that model misspecification wasn't the (only) reason for the poor performance of the previous models.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc1)

#### Exercise \@ref(exr:ch8exc2) {-#ch8solutions2}
We set `file_path` to the path to `estates.xlsx` and then load the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)

View(estates)
```

There are a lot of missing values which can cause problems when fitting the model, so let's remove those:

```{r eval=FALSE}
estates <- na.omit(estates)
```

Next, we fit a linear model and evaluate it with LOOCV using `caret` and `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")
m <- train(selling_price ~ .,
           data = estates,
           method = "lm",
           trControl = tc)
```

The $RMSE$ is 547 and the $MAE$ is 395 kSEK. The average selling price in the data (`mean(estates$selling_price)`) is 2843 kSEK, meaning that the $MAE$ is approximately 13 % of the mean selling price. This is not unreasonably high for this application. Prediction errors are definitely expected here, given the fact that we have relatively few variables - the selling price can be expected to depend on several things not captured by the variables in our data (proximity to schools, access to public transport, and so on). Moreover, houses in Sweden are not sold at fixed prices, but subject to bidding, which can cause prices to fluctuate a lot. All in all, and $MAE$ of 395 is pretty good, and, at the very least, the model seems useful for getting a ballpark figure for the price of a house.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc2)

#### Exercise \@ref(exr:ch8exc3) {-#ch8solutions3}
We set `file_path` to the path to `estates.xlsx` and then load and clean the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)
estates <- na.omit(estates)
```

1. Next, we evaluate the model with 10-fold cross-validation a few times:

```{r eval=FALSE}
library(caret)
# Run this several times:
tc <- trainControl(method = "cv" , number = 10)
m <- train(selling_price ~ .,
           data = estates,
           method = "lm",
           trControl = tc)
m$results
```

In my runs, the $MAE$ ranged from to 391 to 405. Not a massive difference on the scale of the data, but there is clearly some variability in the results.

2. Next, we run repeated 10-fold cross-validations a few times:

```{r eval=FALSE}
# Run this several times:
tc <- trainControl(method = "repeatedcv",
                   number = 10, repeats = 100)
m <- train(selling_price ~ .,
           data = estates,
           method = "lm",
           trControl = tc)
m$results
```

In my runs the $MAE$ varied between 396.0 and 397.4. There is still some variability, but it is much smaller than for a simple 10-fold cross-validation.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc3)

#### Exercise \@ref(exr:ch8exc4) {-#ch8solutions4}
We set `file_path` to the path to `estates.xlsx` and then load and clean the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)
estates <- na.omit(estates)
```

Next, we evaluate the model with the bootstrap a few times:

```{r eval=FALSE}
library(caret)
# Run this several times:
tc <- trainControl(method = "boot",
                   number = 999)
m <- train(selling_price ~ .,
           data = estates,
           method = "lm",
           trControl = tc)
m$results
```

In my run, the $MAE$ varied between 410.0 and 411.8, meaning that the variability is similar to the with repeated 10-fold cross-validation. When I increased the number of bootstrap samples to 9,999, the $MAE$ stabilised around 411.7.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc4)

#### Exercise \@ref(exr:ch8exc5) {-#ch8solutions5}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the two models using `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "repeatedcv",
                   number = 10, repeats = 100,
                   savePredictions = TRUE,
                   classProbs = TRUE)

# Model 1 - two variables:
m <- train(type ~ pH + alcohol,
           data = wine,
           trControl = tc,
           method = "glm",
           family = "binomial")

# Model 2 - four variables:
m2 <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "glm",
           family = "binomial")
```

To compare the models, we use `evalm` to plot ROC and calibration curves:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(list(m, m2),
               gnames = c("Model 1", "Model 2"))

# ROC:
plots$roc

# Calibration curves:
plots$cc
```

Model 2 performs much better, both in terms of $AUC$ and calibration. Adding two more variables has both increased the predictive performance of the model (a much higher $AUC$) and lead to a better-calibrated model.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc5)

#### Exercise \@ref(exr:ch8exc6) {-#ch8solutions6}
First, we load and clean the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)
estates <- na.omit(estates)
```

Next, we fit a ridge regression model and evaluate it with LOOCV using `caret` and `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")
m <- train(selling_price ~ .,
           data = estates,
           method = "glmnet", 
           tuneGrid = expand.grid(alpha = 0,
                                  lambda = seq(0, 10, 0.1)),
           trControl = tc) 

# Results for the best model:
m$results[which(m$results$lambda == m$finalModel$lambdaOpt),]
```

Noticing the the $\lambda$ that gave the best $RMSE$ was 10, which was the maximal $\lambda$ that we investigated, we rerun the code, allowing for higher values of $\lambda$:

```{r eval=FALSE}
m <- train(selling_price ~ .,
           data = estates,
           method = "glmnet", 
           tuneGrid = expand.grid(alpha = 0,
                                  lambda = seq(10, 120, 1)),
           trControl = tc) 

# Results for the best model:
m$results[which(m$results$lambda == m$finalModel$lambdaOpt),]
```

The $RMSE$ is 549 and the $MAE$ is 399. In this case, ridge regression did not improve the performance of the model compared to an ordinary linear regression.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc6)

#### Exercise \@ref(exr:ch8exc6b) {-#ch8solutions6b}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy).

1. We can now fit the models using `train`, making sure to add `family = "binomial"`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10,
                   savePredictions = TRUE,
                   classProbs = TRUE)
m1 <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           method = "glmnet", 
           family = "binomial",
           tuneGrid = expand.grid(alpha = 0,
                                  lambda = seq(0, 10, 0.1)),
           trControl = tc) 

m1
```

The best value for $\lambda$ is 0, meaning that no regularisation is used.

2. Next, we add `summaryFunction = twoClassSummary` and `metric = "ROC"`, which means that $AUC$ and not accuracy will be used to find the optimal $\lambda$:

```{r eval=FALSE}
tc <- trainControl(method = "cv",
                   number = 10,
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)
m2 <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           method = "glmnet", 
           family = "binomial",
           tuneGrid = expand.grid(alpha = 0,
                                  lambda = seq(0, 10, 0.1)),
           metric = "ROC",
           trControl = tc) 

m2
```

The best value for $\lambda$ is still 0. For this dataset, both accuracy and $AUC$ happened to give the same $\lambda$, but that isn't always the case.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc6b)

#### Exercise \@ref(exr:ch8exc7) {-#ch8solutions7}
First, we load and clean the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)
estates <- na.omit(estates)
```

Next, we fit a lasso model and evaluate it with LOOCV using `caret` and `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")
m <- train(selling_price ~ .,
           data = estates,
           method = "glmnet", 
           tuneGrid = expand.grid(alpha = 1,
                                  lambda = seq(0, 10, 0.1)),
           trControl = tc) 

# Results for the best model:
m$results[which(m$results$lambda == m$finalModel$lambdaOpt),]
```

The $RMSE$ is 545 and the $MAE$ is 394. Both are a little lower than for the ordinary linear regression, but the difference is small in this case. To see which variables have been removed, we can use:

```{r eval=FALSE}
coef(m$finalModel, m$finalModel$lambdaOpt)
```

Note that this data isn't perfectly suited to the lasso, because most variables are useful in explaining the selling price. Where the lasso really shines in problems where a lot of the variables, perhaps even most, aren't useful in explaining the response variable. We'll see an example of that in the next exercise.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc7)

#### Exercise \@ref(exr:ch8exc7b) {-#ch8solutions7b}
1. We try fitting a linear model to the data:

```{r eval=FALSE}
m <- lm(y ~ ., data = simulated_data)
summary(m)
```

There are no error messages, but `summary` reveals that there were problems: `Coefficients: (101 not defined because of singularities)` and for half the variables we don't get estimates of the coefficients. It is not possible to fit ordinary linear models when there are more variables than observations (there is no unique solution to the least squares equations from which we obtain the coefficient estimates), which leads to this strange-looking output.

2. Lasso models can be used even when the number of variables is greater than the number of observations - regularisation ensures that there will be a unique solution. We fit a lasso model using `caret` and `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")
m <- train(y ~ .,
           data = simulated_data,
           method = "glmnet", 
           tuneGrid = expand.grid(alpha = 1,
                                  lambda = seq(0, 10, 0.1)),
           trControl = tc) 
```

Next, we have a look at what variables have non-zero coefficients:

```{r eval=FALSE}
rownames(coef(m$finalModel, m$finalModel$lambdaOpt))[
         coef(m$finalModel, m$finalModel$lambdaOpt)[,1]!= 0]
```

Your mileage may vary (try running the simulation more than once!), but it is likely that the lasso will have picked at least the first four of the explanatory variables, probably along with some additional variables. Try changing the ratio between `n` and `p` in your experiment, or the size of the coefficients used when generating `y`, and see what happens.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc7b)

#### Exercise \@ref(exr:ch8exc8) {-#ch8solutions8}
First, we load and clean the data:

```{r eval=FALSE}
library(openxlsx)
estates <- read.xlsx(file_path)
estates <- na.omit(estates)
```

Next, we fit an elastic net model and evaluate it with LOOCV using `caret` and `train`:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")
m <- train(selling_price ~ .,
           data = estates,
           method = "glmnet", 
           tuneGrid = expand.grid(alpha = seq(0, 1, 0.2),
                                  lambda = seq(10, 20, 1)),
           trControl = tc) 

# Print best choices of alpha and lambda:
m$bestTune

# Print the RMSE and MAE for the best model:
m$results[which(rownames(m$results) == rownames(m$bestTune)),]
```

We get a slight improvement over the lasso, with an $RMSE$ of 543.5 and an $MAE$ of 393.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc8)


#### Exercise \@ref(exr:ch8exc10) {-#ch8solutions10}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the model using `train`. We set `summaryFunction = twoClassSummary` and `metric = "ROC"` to use $AUC$ to find the optimal $k$.

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "repeatedcv",
                   number = 10, repeats = 100,
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "rpart",
           metric = "ROC",
           tuneGrid = expand.grid(cp = 0))

m
```

1. Next, we plot the resulting decision tree:

```{r eval=FALSE}
library(rpart.plot)
prp(m$finalModel)
```

The tree is pretty large. The parameter `cp`, called a complexity parameter, can be used to _prune_\index{decision tree!prune} the tree, i.e. to make it smaller. Let's try setting a larger value for `cp`:

```{r eval=FALSE}
m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "rpart",
           metric = "ROC",
           tuneGrid = expand.grid(cp = 0.1))
prp(m$finalModel)
```

That was way too much pruning - now the tree is too small! Try a value somewhere in-between:

```{r eval=FALSE}
m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "rpart",
           metric = "ROC",
           tuneGrid = expand.grid(cp = 0.01))
prp(m$finalModel)
```

That seems like a good compromise. The tree is small enough for us to understand and discuss, but hopefully large enough that it still has a high $AUC$.
  
2. For presentation and interpretability purposes we can experiment with manually setting different values of `cp`. We can also let `train` find an optimal value of `cp` for us, maximising for instance the $AUC$. We'll use `tuneGrid = expand.grid(cp = seq(0, 0.01, 0.001))` to find a good choice of `cp` somewhere between 0 and 0.01:

```{r eval=FALSE}
m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "rpart",
           metric = "ROC",
           tuneGrid = expand.grid(cp = seq(0, 0.01, 0.001)))
m
prp(m$finalModel)
```

In some cases, increasing `cp` can increase the $AUC$, but not here - a `cp` of 0 turns out to be optimal in this instance.

Finally, to visually evaluate the model, we use `evalm` to plot ROC and calibration curves:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(m, gnames = "Decision tree")

# ROC:
plots$roc

# 95 % Confidence interval for AUC:
plots$optres[[1]][13,]

# Calibration curves:
plots$cc
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc10)

#### Exercise \@ref(exr:ch8exc10b) {-#ch8solutions10b}
We set `file_path` to the path of `bacteria.csv`, then load and format the data as in Section \@ref(extrapolation):

```{r eval=FALSE}
bacteria <- read.csv(file_path)
bacteria$Time <- as.POSIXct(bacteria$Time, format = "%H:%M:%S")
```

Next, we fit a regression tree model using rows 45 to 90:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[45:90,],
           trControl = tc,
           method = "rpart",
           tuneGrid = expand.grid(cp = 0))
```

Finally, we make predictions for the entire dataset and compare the results to the actual outcomes:

```{r eval=FALSE}
bacteria$Predicted <- predict(m, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted), colour = "red")
```

Regression trees are unable to extrapolate beyond the training data. By design, they will make constant predictions whenever the values of the explanatory variables go beyond those in the training data. Bear this in mind if you use tree-based models for predictions!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc10b)

#### Exercise \@ref(exr:ch8exc10c) {-#ch8solutions10c}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we fit a classification tree model with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "rpart",
           tuneGrid = expand.grid(cp = 0))
```

Finally, we plot the decision boundaries:

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions <- data.frame(contour_data,
                          Variety = as.numeric(predict(m, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions, colour = "black")
```

The decision boundaries seem pretty good - most points in the lower left part belong to variety 3, most in the middle to variety 1, and most to the right to variety 2.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc10c)

#### Exercise \@ref(exr:ch8exc11) {-#ch8solutions11}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the models using `train` (fitting `m2` takes a while):

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10, 
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m1 <- train(type ~ .,
           data = wine,
           trControl = tc,
           method = "rpart",
           metric = "ROC",
           tuneGrid = expand.grid(cp = c(0, 0.1, 0.01)))

m2 <- train(type ~ .,
           data = wine,
           trControl = tc,
           method = "rf",
           metric = "ROC",
           tuneGrid = expand.grid(mtry = 2:6))
```

Next, we compare the results of the best models:

```{r eval=FALSE}
m1
m2
```

And finally, a visual comparison:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(list(m1, m2),
               gnames = c("Decision tree", "Random forest"))

# ROC:
plots$roc

# Calibration curves:
plots$cc
```

The calibration curves may look worrisome, but the main reason that they deviate from the straight line is that almost all observations have predicted probabilities close to either 0 or 1. To see this, we can have a quick look at the histogram of the predicted probabilities that the wines are white:

```{r eval=FALSE}
hist(predict(m2, type ="prob")[,2])
```

We used 10-fold cross-validation here, as using repeated cross-validation would take too long (at least in this case, where we only study this data as an example). As we've seen before, that means that the performance metrics can vary a lot between runs, so we shouldn't read too much into the difference we found here.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc11)

#### Exercise \@ref(exr:ch8exc11b) {-#ch8solutions11b}
We set `file_path` to the path of `bacteria.csv`, then load and format the data as in Section \@ref(extrapolation):

```{r eval=FALSE}
bacteria <- read.csv(file_path)
bacteria$Time <- as.POSIXct(bacteria$Time, format = "%H:%M:%S")
```

Next, we fit a random forest using rows 45 to 90:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[45:90,],
           trControl = tc,
           method = "rf",
           tuneGrid = expand.grid(mtry = 1))
```

Finally, we make predictions for the entire dataset and compare the results to the actual outcomes:

```{r eval=FALSE}
bacteria$Predicted <- predict(m, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted), colour = "red")
```

The model does very well for the training data, but fails to extrapolate beyond it. Because random forests are based on decision trees, they give constant predictions whenever the values of the explanatory variables go beyond those in the training data.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc11b)

#### Exercise \@ref(exr:ch8exc11c) {-#ch8solutions11c}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we fit a random forest model with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "rf",
           tuneGrid = expand.grid(mtry = 1:2))
```

Finally, we plot the decision boundaries:

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions <- data.frame(contour_data,
                          Variety = as.numeric(predict(m, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions, colour = "black")
```

The decision boundaries are much more complex and flexible than those for the decision tree of Exercise \@ref(exr:ch8exc10c). Perhaps they are too flexible, and the model has overfitted to the training data?

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc11c)

#### Exercise \@ref(exr:ch8exc12) {-#ch8solutions12}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the model using `train`. Try a large number of parameter values to see if you can get a high $AUC$. You can try using a simple 10-fold cross-validation to find reasonable candidate values for the parameters, and then rerun the tuning with a replicated 10-fold cross-validation with parameter values close to those that were optimal in your first search.

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10,
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "gbm",
           metric = "ROC",
           tuneGrid = expand.grid(
                 interaction.depth = 1:5,
                 n.trees = seq(20, 200, 20),
                 shrinkage = seq(0.01, 0.1, 0.01),
                 n.minobsinnode = c(10, 20, 30)),
           verbose = FALSE)

ggplot(m)
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12)

#### Exercise \@ref(exr:ch8exc12a) {-#ch8solutions12a}
We set `file_path` to the path of `bacteria.csv`, then load and format the data as in Section \@ref(extrapolation):

```{r eval=FALSE}
bacteria <- read.csv(file_path)
bacteria$Time <- as.POSIXct(bacteria$Time, format = "%H:%M:%S")
```

Next, we fit a boosted trees model using rows 45 to 90:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[45:90,],
           trControl = tc,
           method = "gbm")
```

Finally, we make predictions for the entire dataset and compare the results to the actual outcomes:

```{r eval=FALSE}
bacteria$Predicted <- predict(m, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted), colour = "red")
```

The model does OK for the training data, but fails to extrapolate beyond it. Because boosted trees models are based on decision trees, they give constant predictions whenever the values of the explanatory variables go beyond those in the training data.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12a)

#### Exercise \@ref(exr:ch8exc12c) {-#ch8solutions12c}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we fit a boosted trees model with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "gbm",
           verbose = FALSE)
```

Finally, we plot the decision boundaries:

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions <- data.frame(contour_data,
                          Variety = as.numeric(predict(m, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions, colour = "black")
```

The decision boundaries are much complex and flexible than those for the decision tree of Exercise \@ref(exr:ch8exc10c), but does not appear to have overfitted like the random forest in Exercise \@ref(exr:ch8exc11c).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12c)

#### Exercise \@ref(exr:ch8exc12ab) {-#ch8solutions12ab}
1. We set `file_path` to the path of `bacteria.csv`, then load and format the data as in Section \@ref(extrapolation):

```{r eval=FALSE}
bacteria <- read.csv(file_path)
bacteria$Time <- as.numeric(as.POSIXct(bacteria$Time, format = "%H:%M:%S"))
```

First, we fit a decision tree using rows 45 to 90:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[45:90,],
           trControl = tc,
           method = "rpart",
           tuneGrid = expand.grid(cp = 0))
```

Next, we fit a model tree using rows 45 to 90. The only explanatory variable available to us is `Time`, and we want to use that both for the models in the nodes and for the splits:

```{r eval=FALSE}
library(partykit)
m2 <- lmtree(OD ~ Time | Time, data = bacteria[45:90,])

library(ggparty)
autoplot(m2)
```

Next, we make predictions for the entire dataset and compare the results to the actual outcomes. We plot the predictions from the decision tree in red and those from the model tree in blue:

```{r eval=FALSE}
bacteria$Predicted_dt <- predict(m, bacteria)
bacteria$Predicted_mt <- predict(m2, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted_dt), colour = "red") +
      geom_line(aes(Time, Predicted_mt), colour = "blue")
```

Neither model does particularly well (but fail in different ways).

2. Next, we repeat the same steps, but use observations 20 to 120 for fitting the models:

```{r eval=FALSE}
m <- train(OD ~ Time,
           data = bacteria[20:120,],
           trControl = tc,
           method = "rpart",
           tuneGrid = expand.grid(cp = 0))

m2 <- lmtree(OD ~ Time | Time, data = bacteria[20:120,])

autoplot(m2)

bacteria$Predicted_dt <- predict(m, bacteria)
bacteria$Predicted_mt <- predict(m2, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted_dt), colour = "red") +
      geom_line(aes(Time, Predicted_mt), colour = "blue")
```

As we can see from the plot of the model tree, it (correctly!) identifies different time phases in which the bacteria grow at different speeds. It therefore also managed to make better extrapolation than the decision tree, which predicts no growth as `Time` is increased beyond what was seen in the training data.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12ab)




#### Exercise \@ref(exr:ch8exc12b) {-#ch8solutions12b}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the model using `train` as follows:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "repeatedcv",
                   number = 10, repeats = 100,
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m <- train(type ~ .,
           data = wine,
           trControl = tc,
           method = "qda",
           metric = "ROC")

m
```

To round things off, we evaluate the model using `evalm`:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(m, gnames = "QDA")

# ROC:
plots$roc

# 95 % Confidence interval for AUC:
plots$optres[[1]][13,]

# Calibration curves:
plots$cc
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12b)

#### Exercise \@ref(exr:ch8exc12ad) {-#ch8solutions12ad}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we fit LDA and QDA models with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m1 <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "lda")

m2 <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "qda")
```

Next, we plot the decision boundaries in the same scatterplot (LDA is black and QDA is orange):

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions1 <- data.frame(contour_data,
                          Variety = as.numeric(predict(m1, contour_data)))
predictions2 <- data.frame(contour_data,
                          Variety = as.numeric(predict(m2, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions1, colour = "black") +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions2, colour = "orange")
```

The decision boundaries are fairly similar and seem pretty reasonable. QDA offers more flexible non-linear boundaries, but the difference isn't huge.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12ad)

#### Exercise \@ref(exr:ch8exc12ae) {-#ch8solutions12ae}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we fit the MDA model with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "mda")
```

Finally, we plot the decision boundaries:

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions <- data.frame(contour_data,
                          Variety = as.numeric(predict(m, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions, colour = "black")
```

The decision boundaries are similar to those of QDA.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12ae)

#### Exercise \@ref(exr:ch8exc12cc) {-#ch8solutions12cc}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We'll go with a polynomial kernel and compare polynomials of degree 2 and 3. We can fit the model using `train` as follows:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10, 
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m <- train(type ~  .,
           data = wine,
           trControl = tc,
           method = "svmPoly",
           tuneGrid = expand.grid(C = 1,
                                  degree = 2:3,
                                  scale = 1),
           metric = "ROC")
```

And, as usual, we can then plot ROC and calibration curves:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(m, gnames = "SVM poly")

# ROC:
plots$roc

# 95 % Confidence interval for AUC:
plots$optres[[1]][13,]

# Calibration curves:
plots$cc
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12cc)

#### Exercise \@ref(exr:ch8exc12d) {-#ch8solutions12d}
1. We set `file_path` to the path of `bacteria.csv`, then load and format the data as in Section \@ref(extrapolation):

```{r eval=FALSE}
bacteria <- read.csv(file_path)
bacteria$Time <- as.POSIXct(bacteria$Time, format = "%H:%M:%S")
```

Next, we fit an SVM with a polynomial kernel using rows 45 to 90:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[45:90,],
           trControl = tc,
           method = "svmPoly")
```

Finally, we make predictions for the entire dataset and compare the results to the actual outcomes:

```{r eval=FALSE}
bacteria$Predicted <- predict(m, bacteria)

library(ggplot2)
ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted), colour = "red")
```

Similar to the linear model in Section \@ref(extrapolation), the SVM model does not extrapolate too well outside the training data. Unlike tree-based models, however, it does not yield constant predictions for values of the explanatory variable that are outside the range in the training data. Instead, the fitted function is assumed to follow the same shape as in the training data.

2. Next, we repeat the same steps using the data from rows 20 to 120:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(OD ~ Time,
           data = bacteria[20:120,],
           trControl = tc,
           method = "svmPoly")

bacteria$Predicted <- predict(m, bacteria)

ggplot(bacteria, aes(Time, OD)) +
    	geom_line() +
    	geom_line(aes(Time, Predicted), colour = "red")
```

The results are disappointing. Using a different kernel could improve the results though, so go ahead and give that a try!

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12d)

#### Exercise \@ref(exr:ch8exc12af) {-#ch8solutions12af}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we two different SVM models with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10)

m1 <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "svmPoly")

m2 <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "svmRadialCost")
```

Next, we plot the decision boundaries in the same scatterplot (the polynomial kernel is black and the radial basis kernel is orange):

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions1 <- data.frame(contour_data,
                          Variety = as.numeric(predict(m1, contour_data)))
predictions2 <- data.frame(contour_data,
                          Variety = as.numeric(predict(m2, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions1, colour = "black") +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions2, colour = "orange")
```

It is likely the case that the polynomial kernel gives a similar results to e.g. MDA, whereas the radial basis kernel gives more flexible decision boundaries.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc12af)

#### Exercise \@ref(exr:ch8exc9) {-#ch8solutions9}
We load and format the data as in the beginning of Section \@ref(classifieraccuracy). We can then fit the model using `train`. We set `summaryFunction = twoClassSummary` and `metric = "ROC"` to use $AUC$ to find the optimal $k$. We make sure to add a `preProcess` argument to `train`, to standardise the data:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "cv",
                   number = 10,
                   summaryFunction = twoClassSummary,
                   savePredictions = TRUE,
                   classProbs = TRUE)

m <- train(type ~ pH + alcohol + fixed.acidity + residual.sugar,
           data = wine,
           trControl = tc,
           method = "knn",
           metric = "ROC",
           tuneLength = 15,
           preProcess = c("center","scale"))

m
```

To visually evaluate the model, we use `evalm` to plot ROC and calibration curves:

```{r eval=FALSE}
library(MLeval)
plots <- evalm(m, gnames = "kNN")

# ROC:
plots$roc

# 95 % Confidence interval for AUC:
plots$optres[[1]][13,]

# Calibration curves:
plots$cc
```

The performance is as good as, or a little better than, the best logistic regression model from Exercise \@ref(exr:ch8exc5). We shouldn't make too much of any differences though, as the models were evaluated in different ways - we used repeated 10-fold cross-validation for the logistics models and a simple 10-fold cross-validation here (because repeated cross-validation would be too slow in this case).

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc9)

#### Exercise \@ref(exr:ch8exc9f) {-#ch8solutions9f}
First, we load the data as in Section \@ref(pca):

```{r eval=FALSE}
# The data is downloaded from the UCI Machine Learning Repository:
# http://archive.ics.uci.edu/ml/datasets/seeds
seeds <- read.table("https://tinyurl.com/seedsdata",
        col.names = c("Area", "Perimeter", "Compactness",
         "Kernel_length", "Kernel_width", "Asymmetry",
         "Groove_length", "Variety"))
seeds$Variety <- factor(seeds$Variety)
```

Next, we two different kNN models with `Kernel_length` and `Compactness` as explanatory variables:

```{r eval=FALSE}
library(caret)
tc <- trainControl(method = "LOOCV")

m <- train(Variety ~ Kernel_length + Compactness,
           data = seeds,
           trControl = tc,
           method = "knn",
           tuneLength = 15,
           preProcess = c("center","scale"))
```

Next, we plot the decision boundaries:

```{r eval=FALSE}
contour_data <- expand.grid(
  Kernel_length = seq(min(seeds$Kernel_length), max(seeds$Kernel_length), length = 500),
  Compactness = seq(min(seeds$Compactness), max(seeds$Compactness), length = 500))

predictions <- data.frame(contour_data,
                          Variety = as.numeric(predict(m, contour_data)))

library(ggplot2)
ggplot(seeds, aes(Kernel_length, Compactness, colour = Variety)) +
      geom_point(size = 2) +
      stat_contour(aes(x = Kernel_length, y = Compactness, z = Variety),
                   data = predictions, colour = "black")
```

The decision boundaries are quite "wiggly", which will always be the case when there are enough points in the sample.

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc9f)


#### Exercise \@ref(exr:ch8exc13) {-#ch8solutions13}
We start by plotting the time series:

```{r eval=FALSE}
library(forecast)
library(fma)

autoplot(writing) +
      ylab("Sales (francs)") +
      ggtitle("Sales of printing and writing paper")
```

Next, we fit an ARIMA model after removing the seasonal component:

```{r eval=FALSE}
tsmod <- stlm(writing, s.window = "periodic",
              modelfunction = auto.arima)
```

The residuals look pretty good for this model:

```{r eval=FALSE}
checkresiduals(tsmod)
```

Finally, we make a forecast for the next 36 months, adding the seasonal component back and using bootstrap prediction intervals:

```{r eval=FALSE}
autoplot(forecast(tsmod, h = 36, bootstrap = TRUE))
```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc13)

<!--#### Exercise \@ref(exr:ch8exc14) {-#ch8solutions14}

```{r eval=FALSE}

```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc14)

 #### Exercise \@ref(exr:ch8exc15) {-#ch8solutions15}

```{r eval=FALSE}

```

`r if (knitr::is_html_output()) '[(Click here to return to the exercise.)]' else '[]'`(#exr:ch8exc15) 

## Chapter 9 {-#ch9solutions}

## Chapter 10 {-#ch10solutions} -->

\vfill
